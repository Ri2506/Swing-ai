{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVqmmUP1sYL5"
      },
      "source": [
        "# ðŸš€ SwingAI Training V4 â€” Colab (Optimized + Tracked)\n",
        "\n",
        "This notebook is a **cleanly split** version of your `SwingAI_Colab_V4_Fixed.py`, with:\n",
        "\n",
        "- âœ… Proper notebook sections (each `# CELL X:` becomes its own cell)\n",
        "- âš¡ Colab T4 optimizations (AMP mixed precision, dataloaders tuned, safer memory patterns)\n",
        "- ðŸ“ˆ Experiment tracking (run folder, config snapshot, CSV metrics, TensorBoard logs, checkpoints)\n",
        "\n",
        "> Tip: If you want logs & checkpoints persisted, mount Google Drive in the next cell.\n"
      ],
      "id": "pVqmmUP1sYL5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbyFoSaFsYL8",
        "outputId": "2c297de7-2e09-4881-be3f-f51726685586"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# (Optional) Mount Google Drive for persistent runs/checkpoints\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Choose where runs are stored (Drive recommended). You can change this.\n",
        "RUNS_BASE_DIR = \"/content/drive/MyDrive/SwingAI_runs\"\n"
      ],
      "id": "ZbyFoSaFsYL8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU-DXB9qsYL9",
        "outputId": "9a0430a7-3ead-4c71-af4f-a253f27c376c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Install complete. Now restart the runtime.\n"
          ]
        }
      ],
      "source": [
        "# âœ… Install (run once, then Runtime â†’ Restart runtime)\n",
        "# Note: Colab already has PyTorch + CUDA. We pin versions that commonly break projects.\n",
        "%pip -q install --upgrade \"pip<25\"\n",
        "%pip -q install \"numpy<2.0\" \"pandas==2.2.2\" \"scipy<1.13\" \"scikit-learn==1.5.2\" \\\n",
        "    \"catboost==1.2.7\" \"yfinance>=0.2.54\" \"curl_cffi>=0.7.4\" \"tensorboard>=2.15\"\n",
        "\n",
        "print(\"âœ… Install complete. Now restart the runtime.\")\n"
      ],
      "id": "XU-DXB9qsYL9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS4J-JFJsYL-",
        "outputId": "a300cf48-0881-4d4f-f0aa-84531cc7f655"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GPU available: True\n",
            "   Tesla T4\n",
            "ðŸ“ RUN_DIR: /content/drive/MyDrive/SwingAI_runs/run_20260107_182456\n"
          ]
        }
      ],
      "source": [
        "# ðŸ”§ Runtime setup (speed + reproducibility + tracking)\n",
        "import os, json, time, random, warnings\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False  # speed > determinism\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"âœ… GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# AMP mixed precision for T4 speed\n",
        "USE_AMP = bool(torch.cuda.is_available())\n",
        "SCALER = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
        "\n",
        "# Run folder (defaults to /content/SwingAI_runs unless you set RUNS_BASE_DIR earlier)\n",
        "RUNS_BASE_DIR = globals().get(\"RUNS_BASE_DIR\", \"/content/SwingAI_runs\")\n",
        "os.makedirs(RUNS_BASE_DIR, exist_ok=True)\n",
        "\n",
        "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = os.path.join(RUNS_BASE_DIR, f\"run_{RUN_ID}\")\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "\n",
        "WRITER = SummaryWriter(log_dir=os.path.join(RUN_DIR, \"tb\"))\n",
        "\n",
        "METRICS_CSV = os.path.join(RUN_DIR, \"metrics.csv\")\n",
        "with open(METRICS_CSV, \"w\") as f:\n",
        "    f.write(\"time,model,split,epoch,metric,value\\n\")\n",
        "\n",
        "def log_metric(model: str, split: str, epoch: int, metric: str, value: float):\n",
        "    t = datetime.now().isoformat(timespec=\"seconds\")\n",
        "    with open(METRICS_CSV, \"a\") as f:\n",
        "        f.write(f\"{t},{model},{split},{epoch},{metric},{value}\\n\")\n",
        "    WRITER.add_scalar(f\"{model}/{split}/{metric}\", float(value), epoch)\n",
        "\n",
        "print(f\"ðŸ“ RUN_DIR: {RUN_DIR}\")\n"
      ],
      "id": "CS4J-JFJsYL-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TD8KtNysYL-"
      },
      "source": [
        "## Sections\n",
        "- CELL 3: Config V4\n",
        "- CELL 4: Download Data\n",
        "- CELL 5: Features V4 (Less aggressive capping)\n",
        "- CELL 6: Dataset (Standard - no balanced sampling for CatBoost)\n",
        "- CELL 7: Soft Focal Loss (reduced gamma)\n",
        "- CELL 8: CatBoost V4 - FIXED!\n",
        "- CELL 9: TFT V4\n",
        "- CELL 10: Stockformer V4\n",
        "- CELL 11: Ensemble Evaluation\n",
        "- CELL 12: Save Models"
      ],
      "id": "7TD8KtNysYL-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hmt630MsYL_"
      },
      "source": [
        "## CELL 3: Config V4"
      ],
      "id": "9hmt630MsYL_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KGyr7LosYL_",
        "outputId": "cc41d8ef-c4fe-481b-c428-64481ffe1eb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Config V4: 40 features\n",
            "âœ… Saved config snapshot\n"
          ]
        }
      ],
      "source": [
        "# CELL 3: Config V4\n",
        "# ============================================================\n",
        "@dataclass\n",
        "class ConfigV4:\n",
        "    LOOKBACK_DAYS: int = 60\n",
        "    PREDICTION_HORIZON: int = 5\n",
        "    MIN_HISTORY_DAYS: int = 252\n",
        "\n",
        "    # Keep balanced thresholds (helped class balance)\n",
        "    UP_THRESHOLD: float = 0.025\n",
        "    DOWN_THRESHOLD: float = -0.015\n",
        "\n",
        "    TRAIN_END: str = \"2024-06-30\"\n",
        "    VAL_END: str = \"2024-09-30\"\n",
        "\n",
        "    # Adjusted weights based on V2 performance\n",
        "    CATBOOST_WEIGHT: float = 0.35\n",
        "    TFT_WEIGHT: float = 0.40\n",
        "    STOCKFORMER_WEIGHT: float = 0.25\n",
        "\n",
        "    BATCH_SIZE: int = 64  # Back to V2 size\n",
        "    LEARNING_RATE: float = 1e-3  # Back to V2\n",
        "    MAX_EPOCHS: int = 50\n",
        "    PATIENCE: int = 10\n",
        "\n",
        "    # CatBoost V4 - FIXED\n",
        "    CATBOOST_ITERATIONS: int = 1500\n",
        "    CATBOOST_DEPTH: int = 7  # Slightly deeper than V2\n",
        "    CATBOOST_LR: float = 0.04\n",
        "    CATBOOST_L2_REG: float = 2.0\n",
        "\n",
        "    # TFT - Between V2 and V3\n",
        "    TFT_HIDDEN_SIZE: int = 96\n",
        "    TFT_ATTENTION_HEADS: int = 6\n",
        "    TFT_DROPOUT: float = 0.15\n",
        "    TFT_NUM_LAYERS: int = 2\n",
        "\n",
        "    # Stockformer - Between V2 and V3\n",
        "    STOCKFORMER_D_MODEL: int = 96\n",
        "    STOCKFORMER_N_HEADS: int = 6\n",
        "    STOCKFORMER_N_LAYERS: int = 2\n",
        "    STOCKFORMER_DROPOUT: float = 0.1\n",
        "\n",
        "    # Loss - REDUCED focal gamma\n",
        "    FOCAL_GAMMA: float = 1.0  # Reduced from 2.0\n",
        "    LABEL_SMOOTHING: float = 0.05  # Reduced from 0.1\n",
        "\n",
        "    NUM_FEATURES: int = 40\n",
        "    MODEL_SAVE_PATH: str = \"/content/drive/MyDrive/SwingAI/models_v4/\"\n",
        "\n",
        "config = ConfigV4()\n",
        "\n",
        "FEATURE_NAMES = [\n",
        "    'return_1d', 'return_5d', 'return_10d', 'return_20d', 'volatility_20d',\n",
        "    'close_to_sma_20', 'close_to_sma_50', 'rsi_14_norm', 'macd_histogram_norm', 'bb_position',\n",
        "    'structure_score', 'range_position', 'dist_to_swing_high', 'dist_to_swing_low',\n",
        "    'in_discount', 'in_deep_discount', 'in_premium', 'near_bullish_ob', 'near_bearish_ob',\n",
        "    'bullish_fvg', 'bearish_fvg', 'sweep_high', 'sweep_low', 'bos_bullish', 'bos_bearish',\n",
        "    'volume_ratio', 'volume_trend', 'obv_slope', 'close_to_vwap',\n",
        "    'buying_pressure', 'accumulation_score', 'big_volume_day', 'higher_high',\n",
        "    'daily_trend', 'weekly_trend', 'monthly_trend', 'mtf_alignment',\n",
        "    'weekly_range_pos', 'monthly_range_pos', 'trend_strength',\n",
        "]\n",
        "\n",
        "print(f\"âœ… Config V4: {len(FEATURE_NAMES)} features\")\n",
        "\n",
        "# ============================================================\n",
        "\n",
        "# --- Colab/T4 extras ---\n",
        "config.SEED = getattr(config, 'SEED', 42)\n",
        "config.NUM_WORKERS = getattr(config, 'NUM_WORKERS', 2)\n",
        "config.PIN_MEMORY = torch.cuda.is_available()\n",
        "config.RUN_DIR = RUN_DIR\n",
        "\n",
        "set_seed(config.SEED)\n",
        "\n",
        "# Save config snapshot\n",
        "with open(os.path.join(RUN_DIR, 'config_v4.json'), 'w') as f:\n",
        "    json.dump(config.__dict__ if hasattr(config, '__dict__') else {}, f, indent=2, default=str)\n",
        "print('âœ… Saved config snapshot')\n"
      ],
      "id": "_KGyr7LosYL_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9KRFb9EsYL_"
      },
      "source": [
        "## CELL 4: Download Data"
      ],
      "id": "N9KRFb9EsYL_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBqrnGljsYMA",
        "outputId": "6de30e92-9f2b-42c5-c46d-d13f8c5deda8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloading 68 stocks...\n",
            "   20/68 | 20 downloaded\n",
            "   40/68 | 40 downloaded\n",
            "   60/68 | 60 downloaded\n",
            "   68/68 | 68 downloaded\n",
            "âœ… Downloaded 68 stocks\n"
          ]
        }
      ],
      "source": [
        "# CELL 4: Download Data\n",
        "# ============================================================\n",
        "FO_STOCKS = [\n",
        "    \"RELIANCE.NS\", \"TCS.NS\", \"HDFCBANK.NS\", \"INFY.NS\", \"ICICIBANK.NS\",\n",
        "    \"HINDUNILVR.NS\", \"SBIN.NS\", \"BHARTIARTL.NS\", \"KOTAKBANK.NS\", \"ITC.NS\",\n",
        "    \"LT.NS\", \"AXISBANK.NS\", \"ASIANPAINT.NS\", \"MARUTI.NS\", \"HCLTECH.NS\",\n",
        "    \"SUNPHARMA.NS\", \"TITAN.NS\", \"BAJFINANCE.NS\", \"ULTRACEMCO.NS\", \"NTPC.NS\",\n",
        "    \"WIPRO.NS\", \"NESTLEIND.NS\", \"POWERGRID.NS\", \"M&M.NS\",\n",
        "    \"JSWSTEEL.NS\", \"ADANIENT.NS\", \"ADANIPORTS.NS\", \"TATASTEEL.NS\", \"ONGC.NS\",\n",
        "    \"TECHM.NS\", \"HDFCLIFE.NS\", \"DIVISLAB.NS\", \"BAJAJFINSV.NS\", \"GRASIM.NS\",\n",
        "    \"DRREDDY.NS\", \"CIPLA.NS\", \"BRITANNIA.NS\", \"EICHERMOT.NS\", \"APOLLOHOSP.NS\",\n",
        "    \"COALINDIA.NS\", \"SBILIFE.NS\", \"BPCL.NS\", \"INDUSINDBK.NS\", \"TATACONSUM.NS\",\n",
        "    \"HEROMOTOCO.NS\", \"HINDALCO.NS\", \"BAJAJ-AUTO.NS\", \"LTIM.NS\", \"SHRIRAMFIN.NS\",\n",
        "    \"TRENT.NS\", \"POLYCAB.NS\", \"PERSISTENT.NS\", \"DIXON.NS\", \"TATAELXSI.NS\",\n",
        "    \"ABB.NS\", \"SIEMENS.NS\", \"HAL.NS\", \"BEL.NS\", \"IRCTC.NS\",\n",
        "    \"COFORGE.NS\", \"MUTHOOTFIN.NS\", \"INDHOTEL.NS\", \"BANKBARODA.NS\",\n",
        "    \"PNB.NS\", \"IDFCFIRSTB.NS\", \"FEDERALBNK.NS\", \"CHOLAFIN.NS\", \"VEDL.NS\",\n",
        "]\n",
        "\n",
        "def yf_download_safe(tickers, start, end, chunk_size=5, max_retries=5, base_sleep=2.0):\n",
        "    out = {}\n",
        "    total = len(tickers)\n",
        "    print(f\"ðŸ“¥ Downloading {total} stocks...\")\n",
        "    for i in range(0, total, chunk_size):\n",
        "        chunk = tickers[i:i+chunk_size]\n",
        "        for attempt in range(1, max_retries + 1):\n",
        "            try:\n",
        "                df = yf.download(\" \".join(chunk), start=start, end=end,\n",
        "                                group_by=\"ticker\", auto_adjust=True,\n",
        "                                threads=False, progress=False)\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    for t in chunk:\n",
        "                        if t in df.columns.get_level_values(0):\n",
        "                            tdf = df[t].dropna(how=\"all\")\n",
        "                            if len(tdf) >= config.MIN_HISTORY_DAYS:\n",
        "                                out[t] = tdf\n",
        "                else:\n",
        "                    if len(df) >= config.MIN_HISTORY_DAYS:\n",
        "                        out[chunk[0]] = df.dropna(how=\"all\")\n",
        "                break\n",
        "            except:\n",
        "                time.sleep(base_sleep * (2 ** (attempt - 1)) + random.random())\n",
        "        done = min(i + chunk_size, total)\n",
        "        if done % 20 == 0 or done == total:\n",
        "            print(f\"   {done}/{total} | {len(out)} downloaded\")\n",
        "        time.sleep(base_sleep + random.random())\n",
        "    print(f\"âœ… Downloaded {len(out)} stocks\")\n",
        "    return out\n",
        "\n",
        "stock_data = yf_download_safe(FO_STOCKS, \"2019-01-01\", \"2024-12-31\")\n",
        "\n",
        "# ============================================================"
      ],
      "id": "zBqrnGljsYMA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LBAxIyrsYMA"
      },
      "source": [
        "## CELL 5: Features V4 (Less aggressive capping)"
      ],
      "id": "-LBAxIyrsYMA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ7aByBUsYMA",
        "outputId": "d59f31cf-de31-4e3a-abc4-fdba206f0a5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”§ Calculating features...\n",
            "âœ… Processed 68 stocks\n"
          ]
        }
      ],
      "source": [
        "# CELL 5: Features V4 (Less aggressive capping)\n",
        "# ============================================================\n",
        "def calculate_features_v4(df):\n",
        "    data = df.copy()\n",
        "\n",
        "    # Price Action (same as V2)\n",
        "    data['return_1d'] = data['Close'].pct_change(1)\n",
        "    data['return_5d'] = data['Close'].pct_change(5)\n",
        "    data['return_10d'] = data['Close'].pct_change(10)\n",
        "    data['return_20d'] = data['Close'].pct_change(20)\n",
        "    data['volatility_20d'] = data['return_1d'].rolling(20).std() * np.sqrt(252)\n",
        "\n",
        "    data['sma_20'] = data['Close'].rolling(20).mean()\n",
        "    data['sma_50'] = data['Close'].rolling(50).mean()\n",
        "    data['close_to_sma_20'] = (data['Close'] - data['sma_20']) / data['sma_20']\n",
        "    data['close_to_sma_50'] = (data['Close'] - data['sma_50']) / data['sma_50']\n",
        "\n",
        "    delta = data['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / (loss + 1e-10)\n",
        "    data['rsi_14_norm'] = (100 - (100 / (1 + rs)) - 50) / 50\n",
        "\n",
        "    ema_12 = data['Close'].ewm(span=12).mean()\n",
        "    ema_26 = data['Close'].ewm(span=26).mean()\n",
        "    macd = ema_12 - ema_26\n",
        "    macd_signal = macd.ewm(span=9).mean()\n",
        "    data['macd_histogram_norm'] = (macd - macd_signal) / data['Close']\n",
        "\n",
        "    bb_mid = data['Close'].rolling(20).mean()\n",
        "    bb_std = data['Close'].rolling(20).std()\n",
        "    bb_upper = bb_mid + 2 * bb_std\n",
        "    bb_lower = bb_mid - 2 * bb_std\n",
        "    data['bb_position'] = (data['Close'] - bb_lower) / (bb_upper - bb_lower + 1e-10)\n",
        "\n",
        "    # SMC/ICT - V4: Use 7-day lookback (between V2's 10 and V3's 5)\n",
        "    data['swing_high'] = data['High'].rolling(7, center=True).max()\n",
        "    data['swing_low'] = data['Low'].rolling(7, center=True).min()\n",
        "    data['prev_swing_high'] = data['swing_high'].shift(7)\n",
        "    data['prev_swing_low'] = data['swing_low'].shift(7)\n",
        "    data['higher_high'] = (data['swing_high'] > data['prev_swing_high']).astype(int)\n",
        "    data['higher_low'] = (data['swing_low'] > data['prev_swing_low']).astype(int)\n",
        "    data['lower_high'] = (data['swing_high'] < data['prev_swing_high']).astype(int)\n",
        "    data['lower_low'] = (data['swing_low'] < data['prev_swing_low']).astype(int)\n",
        "\n",
        "    data['structure_score'] = (data['higher_high'].rolling(5).sum() +\n",
        "                               data['higher_low'].rolling(5).sum() -\n",
        "                               data['lower_high'].rolling(5).sum() -\n",
        "                               data['lower_low'].rolling(5).sum()) / 10\n",
        "\n",
        "    # V4: Use 30-day range (between V2's 50 and V3's 20)\n",
        "    range_high = data['High'].rolling(30).max()\n",
        "    range_low = data['Low'].rolling(30).min()\n",
        "    data['range_position'] = (data['Close'] - range_low) / (range_high - range_low + 1e-10)\n",
        "\n",
        "    # V4: LESS AGGRESSIVE capping (Â±20% instead of Â±15%)\n",
        "    data['dist_to_swing_high'] = np.clip((data['swing_high'] - data['Close']) / data['Close'], -0.20, 0.20)\n",
        "    data['dist_to_swing_low'] = np.clip((data['Close'] - data['swing_low']) / data['Close'], -0.20, 0.20)\n",
        "\n",
        "    data['in_discount'] = (data['range_position'] < 0.5).astype(int)\n",
        "    data['in_deep_discount'] = (data['range_position'] < 0.3).astype(int)\n",
        "    data['in_premium'] = (data['range_position'] > 0.7).astype(int)\n",
        "\n",
        "    vol_threshold = data['return_1d'].rolling(20).std() * 2\n",
        "    data['near_bullish_ob'] = (data['return_1d'] > vol_threshold).rolling(10).sum()\n",
        "    data['near_bearish_ob'] = (data['return_1d'] < -vol_threshold).rolling(10).sum()\n",
        "\n",
        "    data['gap_up'] = ((data['Low'] > data['High'].shift(1)) & (data['return_1d'] > 0.01)).astype(int)\n",
        "    data['gap_down'] = ((data['High'] < data['Low'].shift(1)) & (data['return_1d'] < -0.01)).astype(int)\n",
        "    data['bullish_fvg'] = data['gap_up'].rolling(5).sum()\n",
        "    data['bearish_fvg'] = data['gap_down'].rolling(5).sum()\n",
        "\n",
        "    data['sweep_high'] = ((data['High'] > data['swing_high'].shift(1)) &\n",
        "                          (data['Close'] < data['swing_high'].shift(1))).astype(int)\n",
        "    data['sweep_low'] = ((data['Low'] < data['swing_low'].shift(1)) &\n",
        "                         (data['Close'] > data['swing_low'].shift(1))).astype(int)\n",
        "\n",
        "    data['bos_bullish'] = ((data['Close'] > data['swing_high'].shift(1)) &\n",
        "                           (data['higher_high'] == 1)).astype(int)\n",
        "    data['bos_bearish'] = ((data['Close'] < data['swing_low'].shift(1)) &\n",
        "                           (data['lower_low'] == 1)).astype(int)\n",
        "\n",
        "    # Volume - V4: Cap at 4x (between V2's uncapped and V3's 5x)\n",
        "    data['volume_ma_20'] = data['Volume'].rolling(20).mean()\n",
        "    data['volume_ratio'] = np.clip(data['Volume'] / (data['volume_ma_20'] + 1e-10), 0, 4)\n",
        "    data['volume_trend'] = data['Volume'].rolling(5).mean() / (data['Volume'].rolling(20).mean() + 1e-10)\n",
        "\n",
        "    obv = (np.sign(data['Close'].diff()) * data['Volume']).cumsum()\n",
        "    data['obv_slope'] = obv.diff(5) / (obv.rolling(20).std() + 1e-10)\n",
        "\n",
        "    data['vwap'] = (data['Close'] * data['Volume']).cumsum() / data['Volume'].cumsum()\n",
        "    data['close_to_vwap'] = (data['Close'] - data['vwap']) / (data['vwap'] + 1e-10)\n",
        "\n",
        "    data['buying_pressure'] = (data['Close'] - data['Low']) / (data['High'] - data['Low'] + 1e-10)\n",
        "    data['accumulation_score'] = (data['buying_pressure'] * data['volume_ratio']).rolling(5).mean()\n",
        "    data['big_volume_day'] = (data['volume_ratio'] > 2).astype(int)\n",
        "\n",
        "    # Multi-timeframe (same as V2)\n",
        "    data['daily_trend'] = (data['Close'] > data['sma_20']).astype(int)\n",
        "    data['weekly_close'] = data['Close'].rolling(5).mean()\n",
        "    data['weekly_high'] = data['High'].rolling(5).max()\n",
        "    data['weekly_low'] = data['Low'].rolling(5).min()\n",
        "    data['weekly_trend'] = (data['weekly_close'] > data['weekly_close'].shift(5)).astype(int)\n",
        "    data['monthly_close'] = data['Close'].rolling(21).mean()\n",
        "    data['monthly_trend'] = (data['monthly_close'] > data['monthly_close'].shift(21)).astype(int)\n",
        "    data['mtf_alignment'] = (data['daily_trend'] + data['weekly_trend'] + data['monthly_trend']) / 3\n",
        "    data['weekly_range_pos'] = (data['Close'] - data['weekly_low']) / (data['weekly_high'] - data['weekly_low'] + 1e-10)\n",
        "    data['monthly_range_pos'] = (data['Close'] - data['Low'].rolling(21).min()) / \\\n",
        "                                (data['High'].rolling(21).max() - data['Low'].rolling(21).min() + 1e-10)\n",
        "    data['trend_strength'] = abs(data['close_to_sma_20']) + abs(data['close_to_sma_50'])\n",
        "\n",
        "    features_df = data[FEATURE_NAMES].copy()\n",
        "    features_df = features_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    return features_df\n",
        "\n",
        "def create_labels_v4(df):\n",
        "    forward_return = df['Close'].shift(-config.PREDICTION_HORIZON) / df['Close'] - 1\n",
        "    labels = pd.Series(1, index=df.index)\n",
        "    labels[forward_return >= config.UP_THRESHOLD] = 2\n",
        "    labels[forward_return <= config.DOWN_THRESHOLD] = 0\n",
        "    return labels\n",
        "\n",
        "print(\"ðŸ”§ Calculating features...\")\n",
        "feature_data, labels_data = {}, {}\n",
        "for symbol, data in stock_data.items():\n",
        "    try:\n",
        "        features = calculate_features_v4(data)\n",
        "        labels = create_labels_v4(data)\n",
        "        if len(features) > config.LOOKBACK_DAYS + config.PREDICTION_HORIZON:\n",
        "            feature_data[symbol] = features\n",
        "            labels_data[symbol] = labels\n",
        "    except: pass\n",
        "print(f\"âœ… Processed {len(feature_data)} stocks\")\n",
        "\n",
        "# ============================================================"
      ],
      "id": "LQ7aByBUsYMA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwAT_jkdsYMB"
      },
      "source": [
        "## CELL 6: Dataset (Standard - no balanced sampling for CatBoost)"
      ],
      "id": "LwAT_jkdsYMB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jelSAjZsYMB",
        "outputId": "e0f6faa6-b3d0-45f5-c2b8-4d95d3844f05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Creating sequences...\n",
            "âœ… Total sequences: 95,960\n",
            "ðŸ“Š Train: 87,800 | Val: 4,352 | Test: 3,808\n",
            "ðŸ“Š Test Distribution: SHORT=1493, NEUTRAL=1554, LONG=761\n"
          ]
        }
      ],
      "source": [
        "# CELL 6: Dataset (Standard - no balanced sampling for CatBoost)\n",
        "# ============================================================\n",
        "class SwingDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "    def __len__(self): return len(self.labels)\n",
        "    def __getitem__(self, idx): return {'features': self.features[idx], 'labels': self.labels[idx]}\n",
        "\n",
        "class BalancedSwingDataset(Dataset):\n",
        "    \"\"\"Only for neural networks - with balanced sampling\"\"\"\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "        class_counts = Counter(labels)\n",
        "        total = len(labels)\n",
        "        self.class_weights = {c: total / (3 * count) for c, count in class_counts.items()}\n",
        "        self.sample_weights = torch.FloatTensor([self.class_weights[int(l)] for l in labels])\n",
        "    def __len__(self): return len(self.labels)\n",
        "    def __getitem__(self, idx): return {'features': self.features[idx], 'labels': self.labels[idx]}\n",
        "    def get_sampler(self): return WeightedRandomSampler(self.sample_weights, len(self.sample_weights), True)\n",
        "\n",
        "print(\"ðŸ“Š Creating sequences...\")\n",
        "all_sequences, all_labels, all_dates = [], [], []\n",
        "for symbol in feature_data.keys():\n",
        "    features = feature_data[symbol].values\n",
        "    labels = labels_data[symbol].values\n",
        "    dates = feature_data[symbol].index\n",
        "    for i in range(config.LOOKBACK_DAYS, len(features) - config.PREDICTION_HORIZON):\n",
        "        seq = features[i-config.LOOKBACK_DAYS:i]\n",
        "        label = labels[i]\n",
        "        if not np.isnan(label) and not np.any(np.isnan(seq)):\n",
        "            all_sequences.append(seq)\n",
        "            all_labels.append(int(label))\n",
        "            all_dates.append(dates[i])\n",
        "\n",
        "sequences = np.array(all_sequences)\n",
        "labels_arr = np.array(all_labels)\n",
        "dates_arr = np.array(all_dates)\n",
        "\n",
        "print(f\"âœ… Total sequences: {len(sequences):,}\")\n",
        "\n",
        "train_end = pd.Timestamp(config.TRAIN_END)\n",
        "val_end = pd.Timestamp(config.VAL_END)\n",
        "train_mask = dates_arr <= train_end\n",
        "val_mask = (dates_arr > train_end) & (dates_arr <= val_end)\n",
        "test_mask = dates_arr > val_end\n",
        "\n",
        "# Standard dataset for CatBoost\n",
        "train_dataset = SwingDataset(sequences[train_mask], labels_arr[train_mask])\n",
        "val_dataset = SwingDataset(sequences[val_mask], labels_arr[val_mask])\n",
        "test_dataset = SwingDataset(sequences[test_mask], labels_arr[test_mask])\n",
        "\n",
        "# Balanced dataset for neural networks\n",
        "train_balanced = BalancedSwingDataset(sequences[train_mask], labels_arr[train_mask])\n",
        "\n",
        "print(f\"ðŸ“Š Train: {len(train_dataset):,} | Val: {len(val_dataset):,} | Test: {len(test_dataset):,}\")\n",
        "test_dist = Counter(labels_arr[test_mask])\n",
        "print(f\"ðŸ“Š Test Distribution: SHORT={test_dist[0]}, NEUTRAL={test_dist[1]}, LONG={test_dist[2]}\")\n",
        "\n",
        "# ============================================================"
      ],
      "id": "-jelSAjZsYMB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwvBaa4DsYMB"
      },
      "source": [
        "## CELL 7: Soft Focal Loss (reduced gamma)"
      ],
      "id": "AwvBaa4DsYMB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sa1zpy7sYMB",
        "outputId": "b2448d94-8ac4-40e6-e27b-f17f6bd0312c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Soft Focal Loss (gamma=1.0)\n"
          ]
        }
      ],
      "source": [
        "# CELL 7: Soft Focal Loss (reduced gamma)\n",
        "# ============================================================\n",
        "class SoftFocalLoss(nn.Module):\n",
        "    \"\"\"Focal loss with reduced gamma for less aggressive reweighting\"\"\"\n",
        "    def __init__(self, gamma=1.0, label_smoothing=0.05):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n",
        "        probs = torch.exp(-ce_loss)\n",
        "        focal_weight = (1 - probs) ** self.gamma\n",
        "        return (focal_weight * ce_loss).mean()\n",
        "\n",
        "criterion = SoftFocalLoss(config.FOCAL_GAMMA, config.LABEL_SMOOTHING)\n",
        "print(f\"âœ… Soft Focal Loss (gamma={config.FOCAL_GAMMA})\")\n",
        "\n",
        "# ============================================================"
      ],
      "id": "3Sa1zpy7sYMB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T04kzV0sYMB"
      },
      "source": [
        "## CELL 8: CatBoost V4 - FIXED!"
      ],
      "id": "7T04kzV0sYMB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw7c5J6asYMB",
        "outputId": "afbc84f1-4b19-45a7-b0cc-fc81bf31b5b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸš€ TRAINING CATBOOST V4\n",
            "============================================================\n",
            "Class weights (sqrt): {0: 1.0701389979000506, 1: 0.8927733299701714, 2: 1.0707886402611433}\n",
            "0:\tlearn: 0.4662456\ttest: 0.4746418\tbest: 0.4746418 (0)\ttotal: 156ms\tremaining: 3m 53s\n",
            "100:\tlearn: 0.4931090\ttest: 0.4853324\tbest: 0.4869139 (90)\ttotal: 3.92s\tremaining: 54.2s\n",
            "200:\tlearn: 0.5054776\ttest: 0.4926612\tbest: 0.4935363 (199)\ttotal: 4.83s\tremaining: 31.2s\n",
            "300:\tlearn: 0.5157998\ttest: 0.4942413\tbest: 0.4951579 (291)\ttotal: 5.73s\tremaining: 22.8s\n",
            "400:\tlearn: 0.5241664\ttest: 0.4948638\tbest: 0.4977386 (350)\ttotal: 6.63s\tremaining: 18.2s\n",
            "bestTest = 0.4977385503\n",
            "bestIteration = 350\n",
            "Shrink model to first 351 iterations.\n",
            "âœ… CatBoost Val Accuracy: 0.4071, Macro-F1: 0.4552\n",
            "\n",
            "ðŸ“Š Top 10 Features:\n",
            "   1. dist_to_swing_high: 25.69\n",
            "   2. dist_to_swing_low: 12.83\n",
            "   3. weekly_range_pos: 11.31\n",
            "   4. close_to_vwap: 7.26\n",
            "   5. volatility_20d: 6.26\n",
            "   6. macd_histogram_norm: 3.39\n",
            "   7. volume_trend: 3.17\n",
            "   8. structure_score: 2.63\n",
            "   9. trend_strength: 2.59\n",
            "   10. close_to_sma_50: 2.43\n",
            "âœ… Saved CatBoost model\n"
          ]
        }
      ],
      "source": [
        "# CELL 8: CatBoost V4 - FIXED!\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸš€ TRAINING CATBOOST V4\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "X_train = train_dataset.features[:, -1, :].numpy()\n",
        "y_train = train_dataset.labels.numpy()\n",
        "X_val = val_dataset.features[:, -1, :].numpy()\n",
        "y_val = val_dataset.labels.numpy()\n",
        "\n",
        "# Class weights (not too extreme)\n",
        "class_counts = Counter(y_train)\n",
        "total = len(y_train)\n",
        "# Use sqrt to reduce extreme weights\n",
        "class_weights = {c: np.sqrt(total / (3 * count)) for c, count in class_counts.items()}\n",
        "print(f\"Class weights (sqrt): {class_weights}\")\n",
        "\n",
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=config.CATBOOST_ITERATIONS,\n",
        "    depth=config.CATBOOST_DEPTH,\n",
        "    learning_rate=config.CATBOOST_LR,\n",
        "    l2_leaf_reg=config.CATBOOST_L2_REG,\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='Accuracy',  # FIXED: Changed from TotalF1\n",
        "    random_seed=42,\n",
        "    verbose=100,\n",
        "    early_stopping_rounds=100,  # FIXED: Increased from 50\n",
        "    task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
        "    class_weights=class_weights,\n",
        ")\n",
        "\n",
        "catboost_model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)\n",
        "\n",
        "cat_preds = catboost_model.predict(X_val)\n",
        "cat_acc = (cat_preds == y_val).mean()\n",
        "cat_f1 = f1_score(y_val, cat_preds, average='macro')\n",
        "print(f\"âœ… CatBoost Val Accuracy: {cat_acc:.4f}, Macro-F1: {cat_f1:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "importance = dict(zip(FEATURE_NAMES, catboost_model.feature_importances_))\n",
        "sorted_imp = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "print(\"\\nðŸ“Š Top 10 Features:\")\n",
        "for i, (f, v) in enumerate(sorted_imp):\n",
        "    print(f\"   {i+1}. {f}: {v:.2f}\")\n",
        "\n",
        "# ============================================================\n",
        "\n",
        "# Save CatBoost model\n",
        "try:\n",
        "    catboost_model.save_model(os.path.join(RUN_DIR, 'catboost.cbm'))\n",
        "    print('âœ… Saved CatBoost model')\n",
        "except Exception as e:\n",
        "    print('âš ï¸ CatBoost save failed:', e)\n"
      ],
      "id": "Hw7c5J6asYMB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBajL4YcsYMB"
      },
      "source": [
        "## CELL 9: TFT V4"
      ],
      "id": "hBajL4YcsYMB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3gviHx5sYMC",
        "outputId": "34183de8-e0f3-4489-a428-b37fd55b2d04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸš€ TRAINING TFT V4\n",
            "============================================================\n",
            "Epoch 1: Acc=0.2863, F1=0.2500\n",
            "Epoch 2: Acc=0.4239, F1=0.2903\n",
            "Epoch 3: Acc=0.3387, F1=0.3207\n",
            "Epoch 4: Acc=0.4644, F1=0.3355\n",
            "Epoch 5: Acc=0.4653, F1=0.4517\n",
            "Epoch 6: Acc=0.4216, F1=0.4266\n",
            "Epoch 7: Acc=0.4274, F1=0.4308\n",
            "Epoch 8: Acc=0.4573, F1=0.4500\n",
            "Epoch 9: Acc=0.4708, F1=0.4597\n",
            "Epoch 10: Acc=0.4841, F1=0.4528\n",
            "Epoch 11: Acc=0.4871, F1=0.4569\n",
            "Epoch 12: Acc=0.4304, F1=0.4335\n",
            "Epoch 13: Acc=0.4688, F1=0.4638\n",
            "Epoch 14: Acc=0.5198, F1=0.4596\n",
            "Epoch 15: Acc=0.5000, F1=0.4862\n",
            "Epoch 16: Acc=0.4989, F1=0.4725\n",
            "Epoch 17: Acc=0.4922, F1=0.4666\n",
            "Epoch 18: Acc=0.5211, F1=0.4812\n",
            "Epoch 19: Acc=0.5011, F1=0.4937\n",
            "Epoch 20: Acc=0.5191, F1=0.4963\n",
            "Epoch 21: Acc=0.5221, F1=0.4858\n",
            "Epoch 22: Acc=0.5124, F1=0.4958\n",
            "Epoch 23: Acc=0.5018, F1=0.4869\n",
            "Epoch 24: Acc=0.5110, F1=0.4818\n",
            "Epoch 25: Acc=0.5087, F1=0.4874\n",
            "Epoch 26: Acc=0.5145, F1=0.4933\n",
            "Epoch 27: Acc=0.5039, F1=0.4807\n",
            "Epoch 28: Acc=0.5071, F1=0.4877\n",
            "Epoch 29: Acc=0.5101, F1=0.4891\n",
            "Epoch 30: Acc=0.5078, F1=0.4885\n",
            "Epoch 31: Acc=0.5349, F1=0.4714\n",
            "Epoch 32: Acc=0.5200, F1=0.4725\n",
            "Epoch 33: Acc=0.5023, F1=0.4813\n",
            "Epoch 34: Acc=0.4878, F1=0.4717\n",
            "Epoch 35: Acc=0.5124, F1=0.4856\n",
            "Epoch 36: Acc=0.5048, F1=0.4718\n",
            "Epoch 37: Acc=0.4848, F1=0.4704\n",
            "Epoch 38: Acc=0.4738, F1=0.4691\n",
            "Epoch 39: Acc=0.5000, F1=0.4840\n",
            "Epoch 40: Acc=0.4933, F1=0.4788\n",
            "Epoch 41: Acc=0.4855, F1=0.4632\n",
            "Early stopping at epoch 41\n",
            "âœ… TFT V4 Best Accuracy: 0.5349\n"
          ]
        }
      ],
      "source": [
        "# CELL 9: TFT V4\n",
        "# ============================================================\n",
        "class TFTModelV4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        h = config.TFT_HIDDEN_SIZE\n",
        "        heads = config.TFT_ATTENTION_HEADS\n",
        "        drop = config.TFT_DROPOUT\n",
        "\n",
        "        self.var_sel = nn.Sequential(\n",
        "            nn.Linear(40, h), nn.ReLU(), nn.Dropout(drop), nn.Linear(h, 40), nn.Softmax(dim=-1)\n",
        "        )\n",
        "        self.lstm = nn.LSTM(40, h, config.TFT_NUM_LAYERS, batch_first=True, dropout=drop if config.TFT_NUM_LAYERS > 1 else 0)\n",
        "        self.attention = nn.MultiheadAttention(h, heads, dropout=drop, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(h)\n",
        "        self.grn = nn.Sequential(nn.Linear(h, h), nn.GELU(), nn.Dropout(drop), nn.Linear(h, h))\n",
        "        self.grn_gate = nn.Sequential(nn.Linear(h, h), nn.Sigmoid())\n",
        "        self.grn_norm = nn.LayerNorm(h)\n",
        "        self.output = nn.Linear(h, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        w = self.var_sel(x.mean(1))\n",
        "        x = x * w.unsqueeze(1)\n",
        "        o, _ = self.lstm(x)\n",
        "        a, _ = self.attention(o, o, o)\n",
        "        o = self.norm(o + a)\n",
        "        final = o[:, -1, :]\n",
        "        g = self.grn_gate(final) * self.grn(final)\n",
        "        out = self.grn_norm(final + g)\n",
        "        return self.output(out)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸš€ TRAINING TFT V4\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "tft_model = TFTModelV4().to(DEVICE)\n",
        "# Use balanced sampler for neural networks\n",
        "train_loader = DataLoader(train_balanced, batch_size=config.BATCH_SIZE, sampler=train_balanced.get_sampler(), num_workers=config.NUM_WORKERS, pin_memory=config.PIN_MEMORY, persistent_workers=(config.NUM_WORKERS>0))\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS, pin_memory=config.PIN_MEMORY, persistent_workers=(config.NUM_WORKERS>0))\n",
        "optimizer = torch.optim.AdamW(tft_model.parameters(), lr=config.LEARNING_RATE, weight_decay=0.01)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
        "\n",
        "best_acc, patience_count, best_state = 0, 0, None\n",
        "for epoch in range(config.MAX_EPOCHS):\n",
        "    tft_model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = tft_model(batch['features'].to(DEVICE))\n",
        "        loss = criterion(out, batch['labels'].to(DEVICE))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(tft_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    tft_model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for b in val_loader:\n",
        "            preds.extend(tft_model(b['features'].to(DEVICE)).argmax(1).cpu().numpy())\n",
        "            labels.extend(b['labels'].numpy())\n",
        "\n",
        "    acc = np.mean(np.array(preds) == np.array(labels))\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "    print(f\"Epoch {epoch+1}: Acc={acc:.4f}, F1={f1:.4f}\")\n",
        "    log_metric(\"TFT\", \"val\", epoch+1, \"acc\", acc)\n",
        "    log_metric(\"TFT\", \"val\", epoch+1, \"f1\", f1)\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc, patience_count = acc, 0\n",
        "        best_state = {k: v.cpu().clone() for k, v in tft_model.state_dict().items()}\n",
        "        torch.save(best_state, os.path.join(RUN_DIR, 'tft_best.pt'))\n",
        "    else:\n",
        "        patience_count += 1\n",
        "        if patience_count >= config.PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "tft_model.load_state_dict(best_state)\n",
        "print(f\"âœ… TFT V4 Best Accuracy: {best_acc:.4f}\")\n",
        "\n",
        "# ============================================================"
      ],
      "id": "P3gviHx5sYMC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ad6bv_DsYMC"
      },
      "source": [
        "## CELL 10: Stockformer V4"
      ],
      "id": "5Ad6bv_DsYMC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnOUtmzcsYMC",
        "outputId": "3f5f62fe-6231-44e9-e7a5-7339c912bf5e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸš€ TRAINING STOCKFORMER V4\n",
            "============================================================\n",
            "Epoch 1: Acc=0.4660, F1=0.3086\n",
            "Epoch 2: Acc=0.3656, F1=0.3466\n",
            "Epoch 3: Acc=0.4076, F1=0.3978\n",
            "Epoch 4: Acc=0.4219, F1=0.4138\n",
            "Epoch 5: Acc=0.4320, F1=0.4194\n",
            "Epoch 6: Acc=0.3966, F1=0.3936\n",
            "Epoch 7: Acc=0.4007, F1=0.4010\n",
            "Epoch 8: Acc=0.4412, F1=0.4228\n",
            "Epoch 9: Acc=0.4336, F1=0.4164\n",
            "Epoch 10: Acc=0.4246, F1=0.4114\n",
            "Epoch 11: Acc=0.4258, F1=0.4118\n",
            "Early stopping at epoch 11\n",
            "âœ… Stockformer V4 Best Accuracy: 0.4660\n"
          ]
        }
      ],
      "source": [
        "# CELL 10: Stockformer V4\n",
        "# ============================================================\n",
        "class StockformerV4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        d = config.STOCKFORMER_D_MODEL\n",
        "        h = config.STOCKFORMER_N_HEADS\n",
        "        n = config.STOCKFORMER_N_LAYERS\n",
        "        drop = config.STOCKFORMER_DROPOUT\n",
        "\n",
        "        self.trend_enc = nn.Sequential(nn.Linear(40, d), nn.LayerNorm(d), nn.GELU())\n",
        "        self.seasonal_enc = nn.Sequential(nn.Linear(40, d), nn.LayerNorm(d), nn.GELU())\n",
        "        self.residual_enc = nn.Sequential(nn.Linear(40, d), nn.LayerNorm(d), nn.GELU())\n",
        "\n",
        "        self.pos = nn.Parameter(torch.randn(1, 60, d) * 0.02)\n",
        "\n",
        "        self.trend_tf = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d, h, d*4, drop, batch_first=True), n\n",
        "        )\n",
        "        self.seasonal_tf = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d, h, d*4, drop, batch_first=True), n\n",
        "        )\n",
        "        self.residual_tf = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d, h, d*4, drop, batch_first=True), n\n",
        "        )\n",
        "\n",
        "        self.fusion = nn.Sequential(nn.Linear(d*3, d*2), nn.GELU(), nn.Linear(d*2, d))\n",
        "        self.output = nn.Linear(d, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, s, _ = x.shape\n",
        "        trend = x.cumsum(1) / torch.arange(1, s+1, device=x.device).view(1, -1, 1)\n",
        "        seasonal = x - trend\n",
        "\n",
        "        t = self.trend_tf(self.trend_enc(trend) + self.pos[:, :s])[:, -1]\n",
        "        se = self.seasonal_tf(self.seasonal_enc(seasonal) + self.pos[:, :s])[:, -1]\n",
        "        r = self.residual_tf(self.residual_enc(x) + self.pos[:, :s])[:, -1]\n",
        "\n",
        "        return self.output(self.fusion(torch.cat([t, se, r], -1)))\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸš€ TRAINING STOCKFORMER V4\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sf_model = StockformerV4().to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(sf_model.parameters(), lr=config.LEARNING_RATE, weight_decay=0.01)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
        "\n",
        "best_acc, patience_count, best_state = 0, 0, None\n",
        "for epoch in range(config.MAX_EPOCHS):\n",
        "    sf_model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = sf_model(batch['features'].to(DEVICE))\n",
        "        loss = criterion(out, batch['labels'].to(DEVICE))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(sf_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    sf_model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for b in val_loader:\n",
        "            preds.extend(sf_model(b['features'].to(DEVICE)).argmax(1).cpu().numpy())\n",
        "            labels.extend(b['labels'].numpy())\n",
        "\n",
        "    acc = np.mean(np.array(preds) == np.array(labels))\n",
        "    f1 = f1_score(labels, preds, average='macro')\n",
        "    print(f\"Epoch {epoch+1}: Acc={acc:.4f}, F1={f1:.4f}\")\n",
        "    log_metric(\"Stockformer\", \"val\", epoch+1, \"acc\", acc)\n",
        "    log_metric(\"Stockformer\", \"val\", epoch+1, \"f1\", f1)\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc, patience_count = acc, 0\n",
        "        best_state = {k: v.cpu().clone() for k, v in sf_model.state_dict().items()}\n",
        "        torch.save(best_state, os.path.join(RUN_DIR, 'stockformer_best.pt'))\n",
        "    else:\n",
        "        patience_count += 1\n",
        "        if patience_count >= config.PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "sf_model.load_state_dict(best_state)\n",
        "print(f\"âœ… Stockformer V4 Best Accuracy: {best_acc:.4f}\")\n",
        "\n",
        "# ============================================================"
      ],
      "id": "jnOUtmzcsYMC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emWULJFvsYMC"
      },
      "source": [
        "## CELL 11: Ensemble Evaluation"
      ],
      "id": "emWULJFvsYMC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5SOy7CUsYMC",
        "outputId": "142ba95c-3340-401f-c1c4-e0b6a16eed1a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ðŸ“Š ENSEMBLE EVALUATION V4\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ ENSEMBLE TEST ACCURACY: 0.4803 (48.0%)\n",
            "ðŸŽ¯ ENSEMBLE MACRO-F1: 0.4551\n",
            "\n",
            "ðŸ“‹ Individual Models:\n",
            "   CatBoost:    Acc=0.4727\n",
            "   TFT:         Acc=0.4748\n",
            "   Stockformer: Acc=0.3739\n",
            "\n",
            "ðŸ“ˆ High-Confidence Performance:\n",
            "   Conf >= 50%: 410 (10.8%), Acc=0.7195\n",
            "   Conf >= 60%: 86 (2.3%), Acc=0.8605\n",
            "   Conf >= 70%: 9 (0.2%), Acc=0.8889\n",
            "\n",
            "ðŸ“Š Per-Class Recall:\n",
            "   SHORT: 0.3208\n",
            "   NEUTRAL: 0.6776\n",
            "   LONG: 0.3903\n",
            "\n",
            "ðŸ¤ 3/3 Agreement: 1,688 (44.3%)\n",
            "   Accuracy when all agree: 0.4733\n",
            "\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       SHORT       0.64      0.32      0.43      1493\n",
            "     NEUTRAL       0.46      0.68      0.55      1554\n",
            "        LONG       0.39      0.39      0.39       761\n",
            "\n",
            "    accuracy                           0.48      3808\n",
            "   macro avg       0.50      0.46      0.46      3808\n",
            "weighted avg       0.52      0.48      0.47      3808\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# CELL 11: Ensemble Evaluation\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸ“Š ENSEMBLE EVALUATION V4\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "X_test = test_dataset.features.numpy()\n",
        "y_test = test_dataset.labels.numpy()\n",
        "\n",
        "cat_probs = catboost_model.predict_proba(X_test[:, -1, :])\n",
        "tft_model.eval()\n",
        "sf_model.eval()\n",
        "with torch.no_grad():\n",
        "    tft_probs = F.softmax(tft_model(torch.FloatTensor(X_test).to(DEVICE)), 1).cpu().numpy()\n",
        "    sf_probs = F.softmax(sf_model(torch.FloatTensor(X_test).to(DEVICE)), 1).cpu().numpy()\n",
        "\n",
        "# Static weighted ensemble (simpler, more stable)\n",
        "ensemble_probs = (config.CATBOOST_WEIGHT * cat_probs +\n",
        "                  config.TFT_WEIGHT * tft_probs +\n",
        "                  config.STOCKFORMER_WEIGHT * sf_probs)\n",
        "\n",
        "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
        "ensemble_conf = np.max(ensemble_probs, axis=1)\n",
        "\n",
        "ensemble_acc = (ensemble_preds == y_test).mean()\n",
        "ensemble_f1 = f1_score(y_test, ensemble_preds, average='macro')\n",
        "\n",
        "print(f\"\\nðŸŽ¯ ENSEMBLE TEST ACCURACY: {ensemble_acc:.4f} ({ensemble_acc*100:.1f}%)\")\n",
        "print(f\"ðŸŽ¯ ENSEMBLE MACRO-F1: {ensemble_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ“‹ Individual Models:\")\n",
        "print(f\"   CatBoost:    Acc={np.mean(cat_probs.argmax(1)==y_test):.4f}\")\n",
        "print(f\"   TFT:         Acc={np.mean(tft_probs.argmax(1)==y_test):.4f}\")\n",
        "print(f\"   Stockformer: Acc={np.mean(sf_probs.argmax(1)==y_test):.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ“ˆ High-Confidence Performance:\")\n",
        "for thresh in [0.5, 0.6, 0.7, 0.8]:\n",
        "    mask = ensemble_conf >= thresh\n",
        "    if mask.sum() > 0:\n",
        "        acc = (ensemble_preds[mask] == y_test[mask]).mean()\n",
        "        print(f\"   Conf >= {int(thresh*100)}%: {mask.sum():,} ({mask.mean()*100:.1f}%), Acc={acc:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Per-Class Recall:\")\n",
        "for c, name in [(0, 'SHORT'), (1, 'NEUTRAL'), (2, 'LONG')]:\n",
        "    mask = y_test == c\n",
        "    if mask.sum() > 0:\n",
        "        recall = (ensemble_preds[mask] == c).mean()\n",
        "        print(f\"   {name}: {recall:.4f}\")\n",
        "\n",
        "# Model agreement\n",
        "cat_preds = cat_probs.argmax(1)\n",
        "tft_preds = tft_probs.argmax(1)\n",
        "sf_preds = sf_probs.argmax(1)\n",
        "agreement_3 = (cat_preds == tft_preds) & (tft_preds == sf_preds)\n",
        "print(f\"\\nðŸ¤ 3/3 Agreement: {agreement_3.sum():,} ({agreement_3.mean()*100:.1f}%)\")\n",
        "if agreement_3.sum() > 0:\n",
        "    print(f\"   Accuracy when all agree: {(ensemble_preds[agreement_3] == y_test[agreement_3]).mean():.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(classification_report(y_test, ensemble_preds, target_names=['SHORT', 'NEUTRAL', 'LONG']))\n",
        "\n",
        "# ============================================================"
      ],
      "id": "q5SOy7CUsYMC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HmaGjZ3sYMC"
      },
      "source": [
        "## CELL 12: Save Models"
      ],
      "id": "6HmaGjZ3sYMC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8sqPtcysYMC",
        "outputId": "fe3f8f05-70c4-48e2-cdf2-322c2556000d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ðŸ’¾ Saving V4 models...\n",
            "âœ… V4 Models saved to: /content/drive/MyDrive/SwingAI/models_v4/\n",
            "ðŸŽ‰ Training complete! Accuracy: 48.0%, Macro-F1: 0.4551\n",
            "âœ… Tracking closed. To view TensorBoard in Colab:\n",
            "   %load_ext tensorboard\n",
            "   %tensorboard --logdir /content/drive/MyDrive/SwingAI_runs/run_20260107_182456/tb\n"
          ]
        }
      ],
      "source": [
        "# CELL 12: Save Models\n",
        "# ============================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(config.MODEL_SAVE_PATH, exist_ok=True)\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "print(\"ðŸ’¾ Saving V4 models...\")\n",
        "catboost_model.save_model(f\"{config.MODEL_SAVE_PATH}catboost_v4.cbm\")\n",
        "torch.save(tft_model.state_dict(), f\"{config.MODEL_SAVE_PATH}tft_v4.pt\")\n",
        "torch.save(sf_model.state_dict(), f\"{config.MODEL_SAVE_PATH}stockformer_v4.pt\")\n",
        "\n",
        "model_config = {\n",
        "    \"version\": \"V4_Fixed\",\n",
        "    \"feature_columns\": FEATURE_NAMES,\n",
        "    \"thresholds\": {\"up\": config.UP_THRESHOLD, \"down\": config.DOWN_THRESHOLD},\n",
        "    \"ensemble_weights\": {\"catboost\": config.CATBOOST_WEIGHT, \"tft\": config.TFT_WEIGHT, \"stockformer\": config.STOCKFORMER_WEIGHT},\n",
        "    \"test_accuracy\": float(ensemble_acc),\n",
        "    \"test_macro_f1\": float(ensemble_f1),\n",
        "    \"trained_at\": timestamp\n",
        "}\n",
        "with open(f\"{config.MODEL_SAVE_PATH}model_config_v4.json\", \"w\") as f:\n",
        "    json.dump(model_config, f, indent=2)\n",
        "\n",
        "print(f\"âœ… V4 Models saved to: {config.MODEL_SAVE_PATH}\")\n",
        "print(f\"ðŸŽ‰ Training complete! Accuracy: {ensemble_acc*100:.1f}%, Macro-F1: {ensemble_f1:.4f}\")\n",
        "\n",
        "# Save run summary\n",
        "with open(os.path.join(RUN_DIR, 'run_summary.json'), 'w') as f:\n",
        "    json.dump({\n",
        "        'run_id': RUN_ID,\n",
        "        'run_dir': RUN_DIR,\n",
        "        'created_at': datetime.now().isoformat(timespec='seconds'),\n",
        "    }, f, indent=2)\n",
        "\n",
        "WRITER.flush(); WRITER.close()\n",
        "print('âœ… Tracking closed. To view TensorBoard in Colab:')\n",
        "print('   %load_ext tensorboard')\n",
        "print('   %tensorboard --logdir', os.path.join(RUN_DIR, 'tb'))\n"
      ],
      "id": "y8sqPtcysYMC"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}