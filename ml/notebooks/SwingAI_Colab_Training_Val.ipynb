{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWks1ktxaHxu"
      },
      "source": [
        "# üöÄ SwingAI Training Notebook V2\n",
        "\n",
        "**AI-Powered Swing Trading for Indian Markets**\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Overview\n",
        "\n",
        "This notebook trains the SwingAI ensemble model:\n",
        "- **CatBoost** (35%) - Gradient boosting for tabular data\n",
        "- **TFT** (35%) - Temporal Fusion Transformer for sequences\n",
        "- **Stockformer** (30%) - STL-inspired transformer\n",
        "\n",
        "## üéØ Features\n",
        "- **40 Pure OHLCV Features** (Price Action, SMC/ICT, Volume, MTF)\n",
        "- **No External Dependencies** - Just stock price data\n",
        "- **Rule-Based Filters** - VIX, FII/DII applied separately\n",
        "\n",
        "## ‚öôÔ∏è Requirements\n",
        "- Google Colab with GPU (T4 recommended)\n",
        "- ~2 hours training time\n",
        "- ~5GB RAM\n",
        "\n",
        "---\n",
        "\n",
        "## üì¶ How to Use\n",
        "\n",
        "1. Open in Google Colab\n",
        "2. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
        "3. Run all cells in order\n",
        "4. Models will be saved to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQCr69MGaHxv"
      },
      "source": [
        "## üîç What I fixed (line-by-line level)\n",
        "\n",
        "### 1) Dependencies (Step 1)\n",
        "- Removed the hard pin on `yfinance==0.2.36` (often breaks in Colab due to Yahoo changes).\n",
        "- Added `curl_cffi` (used by modern yfinance internals for more reliable fetching).\n",
        "- Kept PyTorch + CatBoost + sklearn.\n",
        "\n",
        "### 2) Yahoo Finance downloader (Step 3)\n",
        "Your error:\n",
        "- `Expecting value: line 1 column 1` + `No timezone found`\n",
        "\n",
        "Root cause:\n",
        "- Yahoo returns empty/blocked responses when many requests hit quickly (especially with threads in Colab).\n",
        "\n",
        "Fix:\n",
        "- Download in **small chunks**\n",
        "- **threads=False**\n",
        "- **retries** with exponential backoff\n",
        "\n",
        "### 3) Notebook correctness\n",
        "- Ensured the feature engineering cell is a **code cell** (so it actually runs).\n",
        "- Ensured the ‚ÄúTraining Complete‚Äù cell is **markdown** (not executed as Python).\n",
        "\n",
        "If you get a new error later in training (CatBoost / PyTorch / CUDA OOM), paste it and I‚Äôll patch the notebook again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M2QMWm2g0PD",
        "outputId": "71e8b3e4-4209-4c72-85e8-707648656e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.12.0 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.12.0 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "access 1.1.10.post3 requires scipy>=1.14.1, but you have scipy 1.12.0 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m‚úÖ Install done. Now go to Runtime ‚Üí Restart runtime, then run the next cell.\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# Colab-stable dependencies\n",
        "# ==============================\n",
        "\n",
        "# 1) Clean conflicting packages (quiet but forceful)\n",
        "%pip -q uninstall -y numpy pandas scipy scikit-learn catboost yfinance ta curl_cffi\n",
        "\n",
        "# 2) Install a known-stable stack for Colab (CUDA is preinstalled by Colab for torch)\n",
        "#    - Pin numpy < 2.0 to avoid incompatibilities in some libraries\n",
        "#    - Pin pandas/scipy to stable versions\n",
        "#    - Install yfinance + curl_cffi (important for Yahoo throttling issues)\n",
        "%pip -q install \"numpy<2.0\" \"pandas==2.2.2\" \"scipy<1.13\" \"scikit-learn==1.5.2\" \\\n",
        "    \"catboost==1.2.7\" \"yfinance>=0.2.54\" \"curl_cffi>=0.7.4\" \"ta>=0.11.0\"\n",
        "\n",
        "print(\"‚úÖ Install done. Now go to Runtime ‚Üí Restart runtime, then run the next cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13dJV_nEaHxw",
        "outputId": "b94504a6-c507-474e-8a9a-67ff5df5a2b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "numpy: 1.26.4\n",
            "pandas: 2.2.2\n",
            "scipy: 1.12.0\n",
            "sklearn: 1.5.2\n",
            "catboost: 1.2.7\n",
            "yfinance: 1.0\n",
            "torch: 2.9.1+cu128\n",
            "‚úÖ GPU Available: True\n",
            "   Device: Tesla T4\n",
            "‚úÖ GPU Available: True\n",
            "   Device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, pandas as pd, scipy\n",
        "import sklearn\n",
        "import torch\n",
        "import yfinance as yf\n",
        "import catboost\n",
        "import ta\n",
        "\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"pandas:\", pd.__version__)\n",
        "print(\"scipy:\", scipy.__version__)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"catboost:\", catboost.__version__)\n",
        "print(\"yfinance:\", yf.__version__)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"‚úÖ GPU Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"   Device:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "import torch\n",
        "print(f\"‚úÖ GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoLjTYdFaHxw"
      },
      "source": [
        "## üìä Step 2: Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fQK5D4uaHxx",
        "outputId": "d626c0fc-5023-466b-e28f-74c88c03ac2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Config loaded: 40 features\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional\n",
        "from dataclasses import dataclass\n",
        "import yfinance as yf\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "@dataclass\n",
        "class Config:\n",
        "    LOOKBACK_DAYS: int = 60\n",
        "    PREDICTION_HORIZON: int = 5\n",
        "    MIN_HISTORY_DAYS: int = 252\n",
        "    UP_THRESHOLD: float = 0.03\n",
        "    DOWN_THRESHOLD: float = -0.02\n",
        "    TRAIN_END: str = \"2024-06-30\"\n",
        "    VAL_END: str = \"2024-09-30\"\n",
        "    CATBOOST_WEIGHT: float = 0.35\n",
        "    TFT_WEIGHT: float = 0.35\n",
        "    STOCKFORMER_WEIGHT: float = 0.30\n",
        "    BATCH_SIZE: int = 64\n",
        "    LEARNING_RATE: float = 1e-3\n",
        "    MAX_EPOCHS: int = 50\n",
        "    PATIENCE: int = 5\n",
        "    CATBOOST_ITERATIONS: int = 1000\n",
        "    CATBOOST_DEPTH: int = 6\n",
        "    CATBOOST_LR: float = 0.05\n",
        "    TFT_HIDDEN_SIZE: int = 64\n",
        "    TFT_ATTENTION_HEADS: int = 4\n",
        "    TFT_DROPOUT: float = 0.1\n",
        "    STOCKFORMER_D_MODEL: int = 64\n",
        "    STOCKFORMER_N_HEADS: int = 4\n",
        "    STOCKFORMER_N_LAYERS: int = 2\n",
        "    NUM_FEATURES: int = 40\n",
        "    MODEL_SAVE_PATH: str = \"/content/drive/MyDrive/SwingAI/models/\"\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# 40 Features\n",
        "FEATURE_NAMES = [\n",
        "    'return_1d', 'return_5d', 'return_10d', 'return_20d', 'volatility_20d',\n",
        "    'close_to_sma_20', 'close_to_sma_50', 'rsi_14_norm', 'macd_histogram_norm', 'bb_position',\n",
        "    'structure_score', 'range_position', 'dist_to_swing_high', 'dist_to_swing_low',\n",
        "    'in_discount', 'in_deep_discount', 'in_premium', 'near_bullish_ob', 'near_bearish_ob',\n",
        "    'bullish_fvg', 'bearish_fvg', 'sweep_high', 'sweep_low', 'bos_bullish', 'bos_bearish',\n",
        "    'volume_ratio', 'volume_trend', 'obv_slope', 'close_to_vwap',\n",
        "    'buying_pressure', 'accumulation_score', 'big_volume_day', 'higher_high',\n",
        "    'daily_trend', 'weekly_trend', 'monthly_trend', 'mtf_alignment',\n",
        "    'weekly_range_pos', 'monthly_range_pos', 'trend_strength',\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Config loaded: {len(FEATURE_NAMES)} features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNGqbLBqaHxx"
      },
      "source": [
        "## üìà Step 3: Stock Universe & Data Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVkbLl2aaHxx"
      },
      "source": [
        "### ‚úÖ Colab Yahoo Finance download fix (important)\n",
        "\n",
        "If you see errors like **`Expecting value: line 1 column 1`** or **`No timezone found`**, it usually means Yahoo returned an empty/blocked response (rate-limit / throttle).  \n",
        "This notebook uses a **chunked, retrying, threads-disabled downloader** to avoid getting blocked.\n",
        "\n",
        "Key ideas:\n",
        "- **No threads** (threads often triggers throttling in Colab)\n",
        "- **Small chunks** of tickers per request\n",
        "- **Retries** with exponential backoff + jitter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ-YqEe3aHxy",
        "outputId": "9cedd71e-01d6-4b5c-ab2d-97a4877b8b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Downloading 70 stocks (chunk=5, retries=5)...\n",
            "   Progress: 10/70 | downloaded=10\n",
            "   Progress: 20/70 | downloaded=20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:yfinance:HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: TATAMOTORS.NS\"}}}\n",
            "ERROR:yfinance:$TATAMOTORS.NS: possibly delisted; no timezone found\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['TATAMOTORS.NS']: possibly delisted; no timezone found\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Progress: 30/70 | downloaded=29\n",
            "   Progress: 40/70 | downloaded=39\n",
            "   Progress: 50/70 | downloaded=49\n",
            "   Progress: 60/70 | downloaded=59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:yfinance:$ZOMATO.NS: possibly delisted; no timezone found\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['ZOMATO.NS']: possibly delisted; no timezone found\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Progress: 70/70 | downloaded=68\n",
            "‚úÖ Downloaded 68 stocks\n",
            "‚ùó Failed tickers: 2\n",
            "['TATAMOTORS.NS', 'ZOMATO.NS']\n"
          ]
        }
      ],
      "source": [
        "# F&O Stocks universe (edit this list if you want fewer/more tickers)\n",
        "FO_STOCKS = [\n",
        "    \"RELIANCE.NS\", \"TCS.NS\", \"HDFCBANK.NS\", \"INFY.NS\", \"ICICIBANK.NS\",\n",
        "    \"HINDUNILVR.NS\", \"SBIN.NS\", \"BHARTIARTL.NS\", \"KOTAKBANK.NS\", \"ITC.NS\",\n",
        "    \"LT.NS\", \"AXISBANK.NS\", \"ASIANPAINT.NS\", \"MARUTI.NS\", \"HCLTECH.NS\",\n",
        "    \"SUNPHARMA.NS\", \"TITAN.NS\", \"BAJFINANCE.NS\", \"ULTRACEMCO.NS\", \"NTPC.NS\",\n",
        "    \"WIPRO.NS\", \"NESTLEIND.NS\", \"POWERGRID.NS\", \"M&M.NS\", \"TATAMOTORS.NS\",\n",
        "    \"JSWSTEEL.NS\", \"ADANIENT.NS\", \"ADANIPORTS.NS\", \"TATASTEEL.NS\", \"ONGC.NS\",\n",
        "    \"TECHM.NS\", \"HDFCLIFE.NS\", \"DIVISLAB.NS\", \"BAJAJFINSV.NS\", \"GRASIM.NS\",\n",
        "    \"DRREDDY.NS\", \"CIPLA.NS\", \"BRITANNIA.NS\", \"EICHERMOT.NS\", \"APOLLOHOSP.NS\",\n",
        "    \"COALINDIA.NS\", \"SBILIFE.NS\", \"BPCL.NS\", \"INDUSINDBK.NS\", \"TATACONSUM.NS\",\n",
        "    \"HEROMOTOCO.NS\", \"HINDALCO.NS\", \"BAJAJ-AUTO.NS\", \"LTIM.NS\", \"SHRIRAMFIN.NS\",\n",
        "    \"TRENT.NS\", \"POLYCAB.NS\", \"PERSISTENT.NS\", \"DIXON.NS\", \"TATAELXSI.NS\",\n",
        "    \"ABB.NS\", \"SIEMENS.NS\", \"HAL.NS\", \"BEL.NS\", \"IRCTC.NS\",\n",
        "    \"ZOMATO.NS\", \"COFORGE.NS\", \"MUTHOOTFIN.NS\", \"INDHOTEL.NS\", \"BANKBARODA.NS\",\n",
        "    \"PNB.NS\", \"IDFCFIRSTB.NS\", \"FEDERALBNK.NS\", \"CHOLAFIN.NS\", \"VEDL.NS\",\n",
        "]\n",
        "\n",
        "import time, random\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "def yf_download_safe(\n",
        "    tickers,\n",
        "    start: str,\n",
        "    end: str,\n",
        "    interval: str = \"1d\",\n",
        "    auto_adjust: bool = True,\n",
        "    max_retries: int = 5,\n",
        "    chunk_size: int = 5,\n",
        "    base_sleep: float = 1.5,\n",
        "):\n",
        "    \"\"\"Robust yfinance downloader for Google Colab.\n",
        "\n",
        "    Why this exists:\n",
        "    - In Colab, Yahoo frequently rate-limits / returns empty HTML which breaks JSON parsing.\n",
        "    - yfinance then throws: 'Expecting value: line 1 column 1' and 'No timezone found'.\n",
        "\n",
        "    What we do:\n",
        "    - Download tickers in small chunks\n",
        "    - Disable threads (VERY IMPORTANT for Colab)\n",
        "    - Retry with exponential backoff + jitter\n",
        "    \"\"\"\n",
        "    tickers = [t.strip() for t in tickers if isinstance(t, str) and t.strip()]\n",
        "    out = {}\n",
        "\n",
        "    total = len(tickers)\n",
        "    print(f\"üì• Downloading {total} stocks (chunk={chunk_size}, retries={max_retries})...\")\n",
        "\n",
        "    for i in range(0, total, chunk_size):\n",
        "        chunk = tickers[i:i+chunk_size]\n",
        "\n",
        "        success = False\n",
        "        last_err = None\n",
        "\n",
        "        for attempt in range(1, max_retries + 1):\n",
        "            try:\n",
        "                df = yf.download(\n",
        "                    tickers=\" \".join(chunk),\n",
        "                    start=start,\n",
        "                    end=end,\n",
        "                    interval=interval,\n",
        "                    group_by=\"ticker\",\n",
        "                    auto_adjust=auto_adjust,\n",
        "                    threads=False,     # üî• critical for Colab stability\n",
        "                    progress=False,\n",
        "                )\n",
        "\n",
        "                # yfinance returns:\n",
        "                # - MultiIndex columns when multiple tickers\n",
        "                # - Single-level columns for a single ticker\n",
        "                if isinstance(df.columns, pd.MultiIndex):\n",
        "                    for t in chunk:\n",
        "                        if t in df.columns.get_level_values(0):\n",
        "                            tdf = df[t].dropna(how=\"all\")\n",
        "                            if not tdf.empty:\n",
        "                                out[t] = tdf\n",
        "                else:\n",
        "                    # Single ticker case (chunk_size may be 1)\n",
        "                    t = chunk[0]\n",
        "                    tdf = df.dropna(how=\"all\")\n",
        "                    if not tdf.empty:\n",
        "                        out[t] = tdf\n",
        "\n",
        "                success = True\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                last_err = e\n",
        "                # backoff + jitter\n",
        "                sleep_s = base_sleep * (2 ** (attempt - 1)) + random.random()\n",
        "                time.sleep(sleep_s)\n",
        "\n",
        "        # progress\n",
        "        done = min(i + chunk_size, total)\n",
        "        if done % 10 == 0 or done == total:\n",
        "            print(f\"   Progress: {done}/{total} | downloaded={len(out)}\")\n",
        "\n",
        "        if not success and last_err is not None:\n",
        "            print(f\"‚ö†Ô∏è  Chunk failed: {chunk} | last error: {last_err}\")\n",
        "\n",
        "        # small delay between chunks to reduce throttling\n",
        "        time.sleep(base_sleep + random.random())\n",
        "\n",
        "    print(f\"‚úÖ Downloaded {len(out)} stocks\")\n",
        "    return out\n",
        "\n",
        "# Download ~5 years of daily data\n",
        "stock_data = yf_download_safe(FO_STOCKS, start=\"2019-01-01\", end=\"2024-12-31\", interval=\"1d\")\n",
        "\n",
        "# Optional: show which tickers failed (helps debugging)\n",
        "failed = [t for t in FO_STOCKS if t not in stock_data]\n",
        "print(f\"‚ùó Failed tickers: {len(failed)}\")\n",
        "print(failed[:30])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c67ab05SaHxy"
      },
      "source": [
        "#### Tip: If Yahoo blocks you (still)\n",
        "If you still get many failed tickers, try:\n",
        "- Reduce universe for a test run: `FO_STOCKS = FO_STOCKS[:10]`\n",
        "- Increase `base_sleep` to 2.5‚Äì3.0 seconds\n",
        "- Run again (Yahoo throttling is often temporary)\n",
        "\n",
        "This notebook continues even if a few tickers fail ‚Äî it will train on the downloaded set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjmb9de3aHxy",
        "outputId": "c492f436-f6a3-4d2b-b5f4-8924924d033d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Calculating features...\n",
            "‚úÖ Processed 68 stocks\n"
          ]
        }
      ],
      "source": [
        "def calculate_features(df):\n",
        "    \"\"\"Calculate all 40 features from OHLCV data\"\"\"\n",
        "    data = df.copy()\n",
        "\n",
        "    # === PRICE ACTION (10) ===\n",
        "    data['return_1d'] = data['Close'].pct_change(1)\n",
        "    data['return_5d'] = data['Close'].pct_change(5)\n",
        "    data['return_10d'] = data['Close'].pct_change(10)\n",
        "    data['return_20d'] = data['Close'].pct_change(20)\n",
        "    data['volatility_20d'] = data['return_1d'].rolling(20).std() * np.sqrt(252)\n",
        "\n",
        "    data['sma_20'] = data['Close'].rolling(20).mean()\n",
        "    data['sma_50'] = data['Close'].rolling(50).mean()\n",
        "    data['close_to_sma_20'] = (data['Close'] - data['sma_20']) / data['sma_20']\n",
        "    data['close_to_sma_50'] = (data['Close'] - data['sma_50']) / data['sma_50']\n",
        "\n",
        "    # RSI\n",
        "    delta = data['Close'].diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / (loss + 1e-10)\n",
        "    data['rsi_14_norm'] = (100 - (100 / (1 + rs)) - 50) / 50\n",
        "\n",
        "    # MACD\n",
        "    ema_12 = data['Close'].ewm(span=12).mean()\n",
        "    ema_26 = data['Close'].ewm(span=26).mean()\n",
        "    macd = ema_12 - ema_26\n",
        "    macd_signal = macd.ewm(span=9).mean()\n",
        "    data['macd_histogram_norm'] = (macd - macd_signal) / data['Close']\n",
        "\n",
        "    # Bollinger Bands\n",
        "    bb_mid = data['Close'].rolling(20).mean()\n",
        "    bb_std = data['Close'].rolling(20).std()\n",
        "    bb_upper = bb_mid + 2 * bb_std\n",
        "    bb_lower = bb_mid - 2 * bb_std\n",
        "    data['bb_position'] = (data['Close'] - bb_lower) / (bb_upper - bb_lower + 1e-10)\n",
        "\n",
        "    # === SMC/ICT (15) ===\n",
        "    data['swing_high'] = data['High'].rolling(10, center=True).max()\n",
        "    data['swing_low'] = data['Low'].rolling(10, center=True).min()\n",
        "\n",
        "    data['prev_swing_high'] = data['swing_high'].shift(10)\n",
        "    data['prev_swing_low'] = data['swing_low'].shift(10)\n",
        "    data['higher_high'] = (data['swing_high'] > data['prev_swing_high']).astype(int)\n",
        "    data['higher_low'] = (data['swing_low'] > data['prev_swing_low']).astype(int)\n",
        "    data['lower_high'] = (data['swing_high'] < data['prev_swing_high']).astype(int)\n",
        "    data['lower_low'] = (data['swing_low'] < data['prev_swing_low']).astype(int)\n",
        "\n",
        "    data['structure_score'] = (data['higher_high'].rolling(5).sum() +\n",
        "                               data['higher_low'].rolling(5).sum() -\n",
        "                               data['lower_high'].rolling(5).sum() -\n",
        "                               data['lower_low'].rolling(5).sum()) / 10\n",
        "\n",
        "    range_high = data['High'].rolling(50).max()\n",
        "    range_low = data['Low'].rolling(50).min()\n",
        "    data['range_position'] = (data['Close'] - range_low) / (range_high - range_low + 1e-10)\n",
        "\n",
        "    data['dist_to_swing_high'] = (data['swing_high'] - data['Close']) / data['Close']\n",
        "    data['dist_to_swing_low'] = (data['Close'] - data['swing_low']) / data['Close']\n",
        "\n",
        "    data['in_discount'] = (data['range_position'] < 0.5).astype(int)\n",
        "    data['in_deep_discount'] = (data['range_position'] < 0.3).astype(int)\n",
        "    data['in_premium'] = (data['range_position'] > 0.7).astype(int)\n",
        "\n",
        "    vol_threshold = data['return_1d'].rolling(20).std() * 2\n",
        "    data['near_bullish_ob'] = (data['return_1d'] > vol_threshold).rolling(10).sum()\n",
        "    data['near_bearish_ob'] = (data['return_1d'] < -vol_threshold).rolling(10).sum()\n",
        "\n",
        "    data['gap_up'] = ((data['Low'] > data['High'].shift(1)) & (data['return_1d'] > 0.01)).astype(int)\n",
        "    data['gap_down'] = ((data['High'] < data['Low'].shift(1)) & (data['return_1d'] < -0.01)).astype(int)\n",
        "    data['bullish_fvg'] = data['gap_up'].rolling(5).sum()\n",
        "    data['bearish_fvg'] = data['gap_down'].rolling(5).sum()\n",
        "\n",
        "    data['sweep_high'] = ((data['High'] > data['swing_high'].shift(1)) &\n",
        "                          (data['Close'] < data['swing_high'].shift(1))).astype(int)\n",
        "    data['sweep_low'] = ((data['Low'] < data['swing_low'].shift(1)) &\n",
        "                         (data['Close'] > data['swing_low'].shift(1))).astype(int)\n",
        "\n",
        "    data['bos_bullish'] = ((data['Close'] > data['swing_high'].shift(1)) &\n",
        "                           (data['higher_high'] == 1)).astype(int)\n",
        "    data['bos_bearish'] = ((data['Close'] < data['swing_low'].shift(1)) &\n",
        "                           (data['lower_low'] == 1)).astype(int)\n",
        "\n",
        "    # === VOLUME (8) ===\n",
        "    data['volume_ma_20'] = data['Volume'].rolling(20).mean()\n",
        "    data['volume_ratio'] = data['Volume'] / (data['volume_ma_20'] + 1e-10)\n",
        "    data['volume_trend'] = data['Volume'].rolling(5).mean() / (data['Volume'].rolling(20).mean() + 1e-10)\n",
        "\n",
        "    obv = (np.sign(data['Close'].diff()) * data['Volume']).cumsum()\n",
        "    data['obv_slope'] = obv.diff(5) / (obv.rolling(20).std() + 1e-10)\n",
        "\n",
        "    data['vwap'] = (data['Close'] * data['Volume']).cumsum() / data['Volume'].cumsum()\n",
        "    data['close_to_vwap'] = (data['Close'] - data['vwap']) / (data['vwap'] + 1e-10)\n",
        "\n",
        "    data['buying_pressure'] = (data['Close'] - data['Low']) / (data['High'] - data['Low'] + 1e-10)\n",
        "    data['accumulation_score'] = (data['buying_pressure'] * data['volume_ratio']).rolling(5).mean()\n",
        "    data['big_volume_day'] = (data['volume_ratio'] > 2).astype(int)\n",
        "\n",
        "    # === MULTI-TIMEFRAME (7) ===\n",
        "    data['daily_trend'] = (data['Close'] > data['sma_20']).astype(int)\n",
        "\n",
        "    data['weekly_close'] = data['Close'].rolling(5).mean()\n",
        "    data['weekly_high'] = data['High'].rolling(5).max()\n",
        "    data['weekly_low'] = data['Low'].rolling(5).min()\n",
        "    data['weekly_trend'] = (data['weekly_close'] > data['weekly_close'].shift(5)).astype(int)\n",
        "\n",
        "    data['monthly_close'] = data['Close'].rolling(21).mean()\n",
        "    data['monthly_trend'] = (data['monthly_close'] > data['monthly_close'].shift(21)).astype(int)\n",
        "\n",
        "    data['mtf_alignment'] = (data['daily_trend'] + data['weekly_trend'] + data['monthly_trend']) / 3\n",
        "\n",
        "    data['weekly_range_pos'] = (data['Close'] - data['weekly_low']) / (data['weekly_high'] - data['weekly_low'] + 1e-10)\n",
        "    data['monthly_range_pos'] = (data['Close'] - data['Low'].rolling(21).min()) / \\\n",
        "                                (data['High'].rolling(21).max() - data['Low'].rolling(21).min() + 1e-10)\n",
        "\n",
        "    data['trend_strength'] = abs(data['close_to_sma_20']) + abs(data['close_to_sma_50'])\n",
        "\n",
        "    # Select and clean\n",
        "    features_df = data[FEATURE_NAMES].copy()\n",
        "    features_df = features_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    return features_df\n",
        "\n",
        "def create_labels(df):\n",
        "    \"\"\"Create labels: 0=SHORT, 1=NEUTRAL, 2=LONG\"\"\"\n",
        "    forward_return = df['Close'].shift(-config.PREDICTION_HORIZON) / df['Close'] - 1\n",
        "    labels = pd.Series(1, index=df.index)\n",
        "    labels[forward_return >= config.UP_THRESHOLD] = 2   # LONG\n",
        "    labels[forward_return <= config.DOWN_THRESHOLD] = 0  # SHORT\n",
        "    return labels\n",
        "\n",
        "# Calculate features for all stocks\n",
        "print(\"üîß Calculating features...\")\n",
        "feature_data = {}\n",
        "labels_data = {}\n",
        "\n",
        "for symbol, data in stock_data.items():\n",
        "    try:\n",
        "        features = calculate_features(data)\n",
        "        labels = create_labels(data)\n",
        "        if len(features) > config.LOOKBACK_DAYS + config.PREDICTION_HORIZON:\n",
        "            feature_data[symbol] = features\n",
        "            labels_data[symbol] = labels\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(f\"‚úÖ Processed {len(feature_data)} stocks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y-RxPmgaHxz"
      },
      "source": [
        "## üì¶ Step 5: Prepare Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ0WbW5zaHxz",
        "outputId": "cbaa9a3a-33de-4ba2-b822-dd9ded30d0cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Creating sequences...\n",
            "‚úÖ Total sequences: 95,960\n",
            "   Shape: (95960, 60, 40)\n",
            "\n",
            "üìä Dataset Splits:\n",
            "   Train: 87,800\n",
            "   Val:   4,352\n",
            "   Test:  3,808\n"
          ]
        }
      ],
      "source": [
        "class SwingDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'features': self.features[idx], 'labels': self.labels[idx]}\n",
        "\n",
        "# Create sequences\n",
        "print(\"üìä Creating sequences...\")\n",
        "all_sequences, all_labels, all_dates = [], [], []\n",
        "\n",
        "for symbol in feature_data.keys():\n",
        "    features = feature_data[symbol].values\n",
        "    labels = labels_data[symbol].values\n",
        "    dates = feature_data[symbol].index\n",
        "\n",
        "    for i in range(config.LOOKBACK_DAYS, len(features) - config.PREDICTION_HORIZON):\n",
        "        seq = features[i-config.LOOKBACK_DAYS:i]\n",
        "        label = labels[i]\n",
        "        if not np.isnan(label) and not np.any(np.isnan(seq)):\n",
        "            all_sequences.append(seq)\n",
        "            all_labels.append(int(label))\n",
        "            all_dates.append(dates[i])\n",
        "\n",
        "sequences = np.array(all_sequences)\n",
        "labels = np.array(all_labels)\n",
        "dates_arr = np.array(all_dates)\n",
        "\n",
        "print(f\"‚úÖ Total sequences: {len(sequences):,}\")\n",
        "print(f\"   Shape: {sequences.shape}\")\n",
        "\n",
        "# Split by time\n",
        "train_end = pd.Timestamp(config.TRAIN_END)\n",
        "val_end = pd.Timestamp(config.VAL_END)\n",
        "\n",
        "train_mask = dates_arr <= train_end\n",
        "val_mask = (dates_arr > train_end) & (dates_arr <= val_end)\n",
        "test_mask = dates_arr > val_end\n",
        "\n",
        "train_dataset = SwingDataset(sequences[train_mask], labels[train_mask])\n",
        "val_dataset = SwingDataset(sequences[val_mask], labels[val_mask])\n",
        "test_dataset = SwingDataset(sequences[test_mask], labels[test_mask])\n",
        "\n",
        "print(f\"\\nüìä Dataset Splits:\")\n",
        "print(f\"   Train: {len(train_dataset):,}\")\n",
        "print(f\"   Val:   {len(val_dataset):,}\")\n",
        "print(f\"   Test:  {len(test_dataset):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeWWuXokaHxz"
      },
      "source": [
        "## ü§ñ Step 6: Train CatBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfldBdSlaHxz",
        "outputId": "3d528944-67fa-4b41-950b-7215bc72fa9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üöÄ TRAINING CATBOOST MODEL\n",
            "============================================================\n",
            "Training samples: 87,800\n",
            "Features: 40\n",
            "0:\tlearn: 0.5176687\ttest: 0.5393447\tbest: 0.5393447 (0)\ttotal: 25.8ms\tremaining: 25.8s\n",
            "100:\tlearn: 0.5508259\ttest: 0.5688409\tbest: 0.5696328 (94)\ttotal: 906ms\tremaining: 8.06s\n",
            "200:\tlearn: 0.5605168\ttest: 0.5704741\tbest: 0.5717114 (159)\ttotal: 1.61s\tremaining: 6.39s\n",
            "bestTest = 0.5717113719\n",
            "bestIteration = 159\n",
            "Shrink model to first 160 iterations.\n",
            "\n",
            "‚úÖ CatBoost Val Accuracy: 0.4796\n",
            "\n",
            "üìä Top 10 Important Features:\n",
            "   1. dist_to_swing_high: 45.1263\n",
            "   2. dist_to_swing_low: 18.3913\n",
            "   3. weekly_range_pos: 14.2875\n",
            "   4. return_5d: 4.8704\n",
            "   5. volatility_20d: 2.8213\n",
            "   6. close_to_vwap: 2.2493\n",
            "   7. volume_trend: 1.7233\n",
            "   8. macd_histogram_norm: 1.5717\n",
            "   9. structure_score: 1.1442\n",
            "   10. monthly_range_pos: 1.0915\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üöÄ TRAINING CATBOOST MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Prepare data (use last day features for CatBoost)\n",
        "X_train = train_dataset.features[:, -1, :].numpy()\n",
        "y_train = train_dataset.labels.numpy()\n",
        "X_val = val_dataset.features[:, -1, :].numpy()\n",
        "y_val = val_dataset.labels.numpy()\n",
        "\n",
        "print(f\"Training samples: {len(X_train):,}\")\n",
        "print(f\"Features: {X_train.shape[1]}\")\n",
        "\n",
        "# Train CatBoost\n",
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=config.CATBOOST_ITERATIONS,\n",
        "    depth=config.CATBOOST_DEPTH,\n",
        "    learning_rate=config.CATBOOST_LR,\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='Accuracy',\n",
        "    random_seed=42,\n",
        "    verbose=100,\n",
        "    early_stopping_rounds=50,\n",
        "    task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
        "    class_weights={0: 1.2, 1: 0.8, 2: 1.0}\n",
        ")\n",
        "\n",
        "catboost_model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)\n",
        "\n",
        "cat_val_acc = (catboost_model.predict(X_val) == y_val).mean()\n",
        "print(f\"\\n‚úÖ CatBoost Val Accuracy: {cat_val_acc:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "importance = dict(zip(FEATURE_NAMES, catboost_model.feature_importances_))\n",
        "sorted_imp = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nüìä Top 10 Important Features:\")\n",
        "for i, (f, v) in enumerate(sorted_imp[:10]):\n",
        "    print(f\"   {i+1}. {f}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE7VgU6caHxz"
      },
      "source": [
        "## üß† Step 7: Train TFT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU4FbftjaHxz",
        "outputId": "f11053d4-351e-41e5-946c-a67e6ba6e419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üöÄ TRAINING TFT MODEL\n",
            "============================================================\n",
            "Epoch 1: Val Acc = 0.5602\n",
            "Epoch 2: Val Acc = 0.5682\n",
            "Epoch 3: Val Acc = 0.5579\n",
            "Epoch 4: Val Acc = 0.5620\n",
            "Epoch 5: Val Acc = 0.5699\n",
            "Epoch 6: Val Acc = 0.5836\n",
            "Epoch 7: Val Acc = 0.5715\n",
            "Epoch 8: Val Acc = 0.6050\n",
            "Epoch 9: Val Acc = 0.6089\n",
            "Epoch 10: Val Acc = 0.6363\n",
            "Epoch 11: Val Acc = 0.6386\n",
            "Epoch 12: Val Acc = 0.6425\n",
            "Epoch 13: Val Acc = 0.6427\n",
            "Epoch 14: Val Acc = 0.6484\n",
            "Epoch 15: Val Acc = 0.6443\n",
            "Epoch 16: Val Acc = 0.6468\n",
            "Epoch 17: Val Acc = 0.6491\n",
            "Epoch 18: Val Acc = 0.6471\n",
            "Epoch 19: Val Acc = 0.6480\n",
            "Epoch 20: Val Acc = 0.6491\n",
            "Epoch 21: Val Acc = 0.6452\n",
            "Epoch 22: Val Acc = 0.6468\n",
            "Early stopping at epoch 22\n",
            "\n",
            "‚úÖ TFT Best Val Accuracy: 0.6491\n"
          ]
        }
      ],
      "source": [
        "class TFTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        h, heads, drop = config.TFT_HIDDEN_SIZE, config.TFT_ATTENTION_HEADS, config.TFT_DROPOUT\n",
        "\n",
        "        self.var_sel = nn.Sequential(nn.Linear(40, h), nn.ReLU(), nn.Dropout(drop), nn.Linear(h, 40), nn.Softmax(dim=-1))\n",
        "        self.lstm = nn.LSTM(40, h, 2, batch_first=True, dropout=drop)\n",
        "        self.attention = nn.MultiheadAttention(h, heads, dropout=drop, batch_first=True)\n",
        "        self.grn = nn.Sequential(nn.Linear(h, h), nn.GELU(), nn.Dropout(drop), nn.Linear(h, h))\n",
        "        self.grn_gate = nn.Sequential(nn.Linear(h, h), nn.Sigmoid())\n",
        "        self.grn_norm = nn.LayerNorm(h)\n",
        "        self.output = nn.Linear(h, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        w = self.var_sel(x.mean(1))\n",
        "        x = x * w.unsqueeze(1)\n",
        "        o, _ = self.lstm(x)\n",
        "        a, _ = self.attention(o, o, o)\n",
        "        g = self.grn_gate(a) * self.grn(a)\n",
        "        out = self.grn_norm(a + g)\n",
        "        return self.output(out[:, -1, :])\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ TRAINING TFT MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "tft_model = TFTModel().to(DEVICE)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE)\n",
        "optimizer = torch.optim.AdamW(tft_model.parameters(), lr=config.LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_acc, patience_count, best_state = 0, 0, None\n",
        "\n",
        "for epoch in range(config.MAX_EPOCHS):\n",
        "    # Train\n",
        "    tft_model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = tft_model(batch['features'].to(DEVICE))\n",
        "        loss = criterion(out, batch['labels'].to(DEVICE))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(tft_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validate\n",
        "    tft_model.eval()\n",
        "    correct = sum((tft_model(b['features'].to(DEVICE)).argmax(1) == b['labels'].to(DEVICE)).sum().item()\n",
        "                  for b in val_loader)\n",
        "    acc = correct / len(val_dataset)\n",
        "    print(f\"Epoch {epoch+1}: Val Acc = {acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc, patience_count = acc, 0\n",
        "        best_state = {k: v.cpu().clone() for k, v in tft_model.state_dict().items()}\n",
        "    else:\n",
        "        patience_count += 1\n",
        "        if patience_count >= config.PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "tft_model.load_state_dict(best_state)\n",
        "print(f\"\\n‚úÖ TFT Best Val Accuracy: {best_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MS8nuobaHx0"
      },
      "source": [
        "## üî¨ Step 8: Train Stockformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL3mPlR1aHx0",
        "outputId": "d787af2e-1c3d-42cf-b699-425664248e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üöÄ TRAINING STOCKFORMER MODEL\n",
            "============================================================\n",
            "Epoch 1: Val Acc = 0.6006\n",
            "Epoch 2: Val Acc = 0.6085\n",
            "Epoch 3: Val Acc = 0.6108\n",
            "Epoch 4: Val Acc = 0.6181\n",
            "Epoch 5: Val Acc = 0.6080\n",
            "Epoch 6: Val Acc = 0.6183\n",
            "Epoch 7: Val Acc = 0.5944\n",
            "Epoch 8: Val Acc = 0.5990\n",
            "Epoch 9: Val Acc = 0.6032\n",
            "Epoch 10: Val Acc = 0.6057\n",
            "Epoch 11: Val Acc = 0.5935\n",
            "Early stopping at epoch 11\n",
            "\n",
            "‚úÖ Stockformer Best Val Accuracy: 0.6183\n"
          ]
        }
      ],
      "source": [
        "class StockformerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        d, h, l = config.STOCKFORMER_D_MODEL, config.STOCKFORMER_N_HEADS, config.STOCKFORMER_N_LAYERS\n",
        "\n",
        "        self.trend_enc = nn.Sequential(nn.Linear(40, d), nn.LayerNorm(d), nn.GELU())\n",
        "        self.seasonal_enc = nn.Sequential(nn.Linear(40, d), nn.LayerNorm(d), nn.GELU())\n",
        "        self.residual_enc = nn.Sequential(nn.Linear(40, d), nn.LayerNorm(d), nn.GELU())\n",
        "\n",
        "        self.pos = nn.Parameter(torch.randn(1, 60, d) * 0.02)\n",
        "\n",
        "        enc = nn.TransformerEncoderLayer(d, h, d*4, 0.1, batch_first=True)\n",
        "        self.trend_tf = nn.TransformerEncoder(enc, l)\n",
        "        self.seasonal_tf = nn.TransformerEncoder(nn.TransformerEncoderLayer(d, h, d*4, 0.1, batch_first=True), l)\n",
        "        self.residual_tf = nn.TransformerEncoder(nn.TransformerEncoderLayer(d, h, d*4, 0.1, batch_first=True), l)\n",
        "\n",
        "        self.fusion = nn.Sequential(nn.Linear(d*3, d*2), nn.GELU(), nn.Linear(d*2, d))\n",
        "        self.output = nn.Linear(d, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, s, _ = x.shape\n",
        "        trend = x.cumsum(1) / torch.arange(1, s+1, device=x.device).view(1, -1, 1)\n",
        "        seasonal = x - trend\n",
        "\n",
        "        t = self.trend_tf(self.trend_enc(trend) + self.pos[:, :s])[:, -1]\n",
        "        se = self.seasonal_tf(self.seasonal_enc(seasonal) + self.pos[:, :s])[:, -1]\n",
        "        r = self.residual_tf(self.residual_enc(x) + self.pos[:, :s])[:, -1]\n",
        "\n",
        "        return self.output(self.fusion(torch.cat([t, se, r], -1)))\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ TRAINING STOCKFORMER MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sf_model = StockformerModel().to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(sf_model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "best_acc, patience_count, best_state = 0, 0, None\n",
        "\n",
        "for epoch in range(config.MAX_EPOCHS):\n",
        "    # Train\n",
        "    sf_model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = sf_model(batch['features'].to(DEVICE))\n",
        "        loss = criterion(out, batch['labels'].to(DEVICE))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(sf_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validate\n",
        "    sf_model.eval()\n",
        "    correct = sum((sf_model(b['features'].to(DEVICE)).argmax(1) == b['labels'].to(DEVICE)).sum().item()\n",
        "                  for b in val_loader)\n",
        "    acc = correct / len(val_dataset)\n",
        "    print(f\"Epoch {epoch+1}: Val Acc = {acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc, patience_count = acc, 0\n",
        "        best_state = {k: v.cpu().clone() for k, v in sf_model.state_dict().items()}\n",
        "    else:\n",
        "        patience_count += 1\n",
        "        if patience_count >= config.PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "sf_model.load_state_dict(best_state)\n",
        "print(f\"\\n‚úÖ Stockformer Best Val Accuracy: {best_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTo6yA-LaHx0"
      },
      "source": [
        "## üìä Step 9: Ensemble Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZMMKj2PaHx0",
        "outputId": "7c87c6b4-a89c-41ad-c1b0-fb17557215ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìä ENSEMBLE EVALUATION ON TEST SET\n",
            "============================================================\n",
            "\n",
            "üéØ ENSEMBLE TEST ACCURACY: 0.5825 (58.2%)\n",
            "\n",
            "üìã Individual Model Accuracy:\n",
            "   CatBoost:    0.5701\n",
            "   TFT:         0.5822\n",
            "   Stockformer: 0.5607\n",
            "\n",
            "ü§ù Agreement Analysis:\n",
            "   1/3 agree: 163 samples, accuracy: 0.4601\n",
            "   2/3 agree: 888 samples, accuracy: 0.5090\n",
            "   3/3 agree: 2,755 samples, accuracy: 0.6134\n",
            "\n",
            "üìà Confidence Analysis:\n",
            "   Conf >= 60%: 1,443 (37.9%), accuracy: 0.6715\n",
            "   Conf >= 70%: 280 (7.4%), accuracy: 0.8214\n",
            "   Conf >= 80%: 58 (1.5%), accuracy: 0.9655\n",
            "\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       SHORT       0.75      0.29      0.41      1300\n",
            "     NEUTRAL       0.55      0.90      0.69      1879\n",
            "        LONG       0.61      0.24      0.35       629\n",
            "\n",
            "    accuracy                           0.58      3808\n",
            "   macro avg       0.64      0.48      0.48      3808\n",
            "weighted avg       0.63      0.58      0.54      3808\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìä ENSEMBLE EVALUATION ON TEST SET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get test data\n",
        "X_test = test_dataset.features.numpy()\n",
        "y_test = test_dataset.labels.numpy()\n",
        "\n",
        "# CatBoost predictions\n",
        "cat_probs = catboost_model.predict_proba(X_test[:, -1, :])\n",
        "\n",
        "# TFT predictions\n",
        "tft_model.eval()\n",
        "with torch.no_grad():\n",
        "    tft_probs = torch.softmax(tft_model(torch.FloatTensor(X_test).to(DEVICE)), 1).cpu().numpy()\n",
        "\n",
        "# Stockformer predictions\n",
        "sf_model.eval()\n",
        "with torch.no_grad():\n",
        "    sf_probs = torch.softmax(sf_model(torch.FloatTensor(X_test).to(DEVICE)), 1).cpu().numpy()\n",
        "\n",
        "# Ensemble (weighted average)\n",
        "ensemble_probs = (config.CATBOOST_WEIGHT * cat_probs +\n",
        "                  config.TFT_WEIGHT * tft_probs +\n",
        "                  config.STOCKFORMER_WEIGHT * sf_probs)\n",
        "\n",
        "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
        "ensemble_conf = np.max(ensemble_probs, axis=1)\n",
        "ensemble_acc = (ensemble_preds == y_test).mean()\n",
        "\n",
        "print(f\"\\nüéØ ENSEMBLE TEST ACCURACY: {ensemble_acc:.4f} ({ensemble_acc*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nüìã Individual Model Accuracy:\")\n",
        "print(f\"   CatBoost:    {(np.argmax(cat_probs, 1) == y_test).mean():.4f}\")\n",
        "print(f\"   TFT:         {(np.argmax(tft_probs, 1) == y_test).mean():.4f}\")\n",
        "print(f\"   Stockformer: {(np.argmax(sf_probs, 1) == y_test).mean():.4f}\")\n",
        "\n",
        "# Model agreement analysis\n",
        "cat_preds = np.argmax(cat_probs, axis=1)\n",
        "tft_preds = np.argmax(tft_probs, axis=1)\n",
        "sf_preds = np.argmax(sf_probs, axis=1)\n",
        "all_preds = np.stack([cat_preds, tft_preds, sf_preds], axis=1)\n",
        "agreements = (all_preds == ensemble_preds[:, None]).sum(axis=1)\n",
        "\n",
        "print(f\"\\nü§ù Agreement Analysis:\")\n",
        "for i in [1, 2, 3]:\n",
        "    mask = agreements == i\n",
        "    if mask.sum() > 0:\n",
        "        acc = (ensemble_preds[mask] == y_test[mask]).mean()\n",
        "        print(f\"   {i}/3 agree: {mask.sum():,} samples, accuracy: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\nüìà Confidence Analysis:\")\n",
        "for thresh in [60, 70, 80]:\n",
        "    mask = ensemble_conf * 100 >= thresh\n",
        "    if mask.sum() > 0:\n",
        "        acc = (ensemble_preds[mask] == y_test[mask]).mean()\n",
        "        print(f\"   Conf >= {thresh}%: {mask.sum():,} ({mask.mean()*100:.1f}%), accuracy: {acc:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(classification_report(y_test, ensemble_preds, target_names=['SHORT', 'NEUTRAL', 'LONG']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMNLiOPMaHx0"
      },
      "source": [
        "## üíæ Step 10: Save Models to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ8v9B4waHx0",
        "outputId": "148426e3-303c-4879-b689-bcaf14ce0c3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "üíæ Saving models...\n",
            "\n",
            "‚úÖ All models saved to: /content/drive/MyDrive/SwingAI/models/\n",
            "   üìÅ catboost_model.cbm\n",
            "   üìÅ tft_model.pt\n",
            "   üìÅ stockformer_model.pt\n",
            "   üìÅ model_config.json\n",
            "\n",
            "üéâ Training complete! Test accuracy: 58.2%\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create save directory\n",
        "os.makedirs(config.MODEL_SAVE_PATH, exist_ok=True)\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "print(\"üíæ Saving models...\")\n",
        "\n",
        "# Save CatBoost\n",
        "catboost_model.save_model(f\"{config.MODEL_SAVE_PATH}catboost_model.cbm\")\n",
        "\n",
        "# Save TFT\n",
        "torch.save(tft_model.state_dict(), f\"{config.MODEL_SAVE_PATH}tft_model.pt\")\n",
        "\n",
        "# Save Stockformer\n",
        "torch.save(sf_model.state_dict(), f\"{config.MODEL_SAVE_PATH}stockformer_model.pt\")\n",
        "\n",
        "# Save config and features\n",
        "model_config = {\n",
        "    \"feature_columns\": FEATURE_NAMES,\n",
        "    \"num_features\": 40,\n",
        "    \"lookback_days\": config.LOOKBACK_DAYS,\n",
        "    \"ensemble_weights\": {\n",
        "        \"catboost\": config.CATBOOST_WEIGHT,\n",
        "        \"tft\": config.TFT_WEIGHT,\n",
        "        \"stockformer\": config.STOCKFORMER_WEIGHT\n",
        "    },\n",
        "    \"thresholds\": {\n",
        "        \"up\": config.UP_THRESHOLD,\n",
        "        \"down\": config.DOWN_THRESHOLD\n",
        "    },\n",
        "    \"test_accuracy\": float(ensemble_acc),\n",
        "    \"trained_at\": timestamp\n",
        "}\n",
        "\n",
        "with open(f\"{config.MODEL_SAVE_PATH}model_config.json\", \"w\") as f:\n",
        "    json.dump(model_config, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ All models saved to: {config.MODEL_SAVE_PATH}\")\n",
        "print(f\"   üìÅ catboost_model.cbm\")\n",
        "print(f\"   üìÅ tft_model.pt\")\n",
        "print(f\"   üìÅ stockformer_model.pt\")\n",
        "print(f\"   üìÅ model_config.json\")\n",
        "print(f\"\\nüéâ Training complete! Test accuracy: {ensemble_acc*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hLZvCqYaHx0"
      },
      "source": [
        "## üéâ Training Complete!\n",
        "\n",
        "Your models are saved to Google Drive. Download them and upload to Modal for production inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSDQOxr8aHx0"
      },
      "source": [
        "---\n",
        "**Next Steps:**\n",
        "1. Download models from Google Drive\n",
        "2. Upload to Modal volume using `ml/inference/modal_inference.py`\n",
        "3. Deploy backend to Railway\n",
        "4. Test signal generation!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
